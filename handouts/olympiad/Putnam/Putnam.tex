\documentclass[11pt]{scrartcl}
\usepackage[sexy]{evan}
\usepackage{graphicx}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb C}
\newcommand{\T}{\mathbb T}
\newcommand{\PP}{\mathbb P}
\newcommand{\supp}{\text{supp }}
\newcommand{\<}{\langle}
\renewcommand{\>}{\rangle}
\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}


\let \phi \varphi
\let \bar \overline

%From Topology
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cH}{\mathcal{H}}

\usepackage{answers}
\Newassociation{hint}{hintitem}{all-hints}
\renewcommand{\solutionextension}{out}
\renewenvironment{hintitem}[1]{\item[\bfseries #1.]}{}
\declaretheorem[style=thmbluebox,name={Problem}]{Prob}

\begin{document}
\title{Putnam Solutions}
\author{Vishal Raman}
\maketitle
\begin{abstract}
My sketches to problems from the Putnam exams.   I tend to leave out a lot of the details for routine checks or brute force calculations.  Any typos or mistakes found are mine - kindly direct them to my inbox.
\end{abstract}
\tableofcontents
\pagebreak
%\section{Putnam 1985}
%\subsection{A1 - Combinatorics} 
%\begin{Prob} Determine with proof, the number of ordered triples $(A, B, C)$ with $A\cup B\cup C = \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$ and $A \cap B \cap C = \emptyset$.   
%\end{Prob}
%\begin{proof}
%The Venn Diagram for $A, B, C$ has $7$ regions and we can place integers $1$ through $10$ in any of the regions except for the one corresponding to $A \cap B \cap C$.  This leads to $6^{10} = \boxed{2^{10} 3^{10} 5^0 7^0}$ possible ordered triples, since each configuration corresponds to a unique triple.  
%\end{proof}
%\subsection{A2 - Geometry}
%\begin{Prob} Let $T$ be an acute triangle. Inscribe a rectangle $R$ in $T$ with one side along a side of $T$. Then inscribe a rectangle $S$ in the triangle formed by the side of $R$ opposite the side on the boundary of $T$, and the other two sides of $T$, with one side along the side of $R$. For any polygon $X$, let $A(X)$ denote the area of $X$. Find the maximum value, or show that no maximum exists, of $\frac{A(R) + A(S)}{A(T)}$, where $T$ ranges over all triangles and $R, S$ over all rectangles as above.
%\end{Prob}
%\begin{proof}
%Drop a perpendicular from a vertex.  It suffices to maximize the ratio of areas for the left half since the ratio stays the same reflecting the triangle about the axis.  Let the height of the resulting triangle be $H$, the length $L$.  Split the height into 3 smaller heights $h_1, h_2, h_3$ so that $h_1 + h_2 + h_3 = H$.  Drawing a line parallel to the length through the heights gives the rectangles.  The lengths of the rectangles are
%$$\ell_1 = \frac{L}{H}h_1, \ell_2 = \frac{L}{H}(h_1 + h_2).$$
%
%The ratio is then given by 
%$$\gamma = \frac{A(R) + A(S)}{A(T)} = \frac{h_2\ell_1 + h_3\ell_2}{LH/2} = \frac{h_1h_2L/H + h_3(h_1+h_2)L/H}{LH/2} = \frac{2h_1h_2 + 2h_2h_3 + 2h_3h_1}{H^2}.$$
%Note that 
%$$H^2 = (h_1+h_2+h_3)^2 = h_1^2 + h_2^2 + h_3^2 + 2h_1h_2 + 2h_2h_3 + 2h_3h_1,$$
%so it follows that 
%$$\gamma = 1 - \frac{h_1^2+h_2^2+h_3^2}{(h_1+h_2+h_3)^2}.$$
%By the Cauchy-Schwarz Inequality,
%$$(h_1^2+h_2^2+h_3^2)(1+1+1) \ge (h_1+h_2+h_3)^2$$
%with equality when $h_1=h_2=h_3$.  Hence, $\gamma \le \boxed{2/3}$.  It is easy to show the equality case for an equilateral triangle of height $1$ with $h_1=h_2=h_3 = 1/3$.
%\end{proof}
%\subsection{A3 - Analysis}
%\begin{proof}  We claim that 
%$$\lim_{n \to \infty} a_n(n) = \begin{cases} 0, d = 0 \\
%e^{d}-1, d \ne 0
%\end{cases}.$$
%The $d=0$ case is clear, so we show the case where $d \ne 0$.  First, we prove that $a_m(n)+1 = (a_n(0)+1)^{2^{m}}.$  Note that $a_1(1) + 1 = a_1(0)^2 + 2a_1(0) + 1 = (a_1(0) + 1)^2$.  Suppose $a_n(k) + 1 = (a_n(0)+1)^{2^{k}}$ for some $k \in \N$.  Then
%$$a_{n}(k+1)+1 = a_{n}(k)^2 + 2a_n(k)+1 = (a_n(k) + 1)^2 = ((a_n(0)+1)^{2^k})^2 = (a_n(0) + 1)^{2^{k+1}},$$
%as desired.
%
%Plugging in the value of $a_n(0)$, we find that 
%$$a_n(n) = \left (\frac{d}{2^n} + 1\right )^{2^n} - 1 = \left (\frac{d}{2^n} + 1\right )^{\frac{2^n}{d} \cdot d} - 1.$$
%Taking the limit as $n \to \infty$, we find that 
%$$\lim_{n \to \infty} a_n(n) = \lim_{n \to \infty} \left (\frac{d}{2^n} + 1\right )^{\frac{2^n}{d} \cdot d} - 1 \xrightarrow{m = 2^n/d} \lim_{m \to \infty} \left (1+\frac{1}{m}\right )^{md} - 1 = e^{d} - 1.$$
%\end{proof}
%\pagebreak
\section{Putnam - 2001}
\subsection{A1 - Algebra}
 Consider a set $S$ and a binary operation $*$.  Assume $(a*b)*a = b$ for all $a, b \in S$.  Prove that $a*(b*a) = b$ for all $a, b \in S$. 
\begin{proof}
Note that 
$$b = ((b*a)*b) * (b*a) = a * (b * a).$$
\end{proof}
\subsection{A2 - Combinatorics}
You have coins $C_1, C_2, \dots, C_n$.  For each $k$, $C_k$ is biased so that when tossed, is has probability $1/(2k+1)$ of falling heads.  If the $n$ coins are tossed, what is the probability that the number of heads is odd?

\begin{proof}
We claim the probability is $P(n) = \boxed{\frac{n}{2n+1}}$.  We prove it by induction.  We are given that $P(1) = \frac{1}{3}$, which satisfies the claim.  Suppose $P(k) = \frac{k}{2k+1}$ for $k \ge 1$.  In order to find $P(k+1)$, we condition on the result of the first $k$ coin tosses.  Namely, suppose the number of heads is even after $k$ tosses.  Then, the total number of heads is odd if we flip a head on the $k+1$-th toss.  Similarly, if the number of heads is odd after $k$ tosses, then the total number of heads is odd if we flip a tail on the $k+1$-th toss.  

Putting this together gives 
\begin{align*}
P(k+1) &= (1 - P(k))p_{k+1} + P(k)(1 - p_{k+1}) \\
&= P(k)\left (1 - 2p_{k+1}\right ) + p_{k+1} \\
&= P(k) \left (1 - \frac{2}{2k+3}\right ) + \frac{1}{2k+3} \\
&= P(k) \frac{2k+1}{2k+3} + \frac{1}{2k+3} \\
&= \frac{k}{2k+1} \frac{2k+1}{2k+3} + \frac{1}{2k+3} \\
&=\frac{k+1}{2k+3}
\end{align*}
which proves the result.
\end{proof}

\subsubsection{Official Solution}
There is another remarkable proof using generating functions.
\begin{proof}
Consider the polynomial $f(x) = \prod_{k=1}^n \left (\frac{x}{2k+1} + \frac{2k}{2k+1} \right)$.  The coefficient of $x^m$ gives the probability of exactly $m$ heads.  The sum of the odd coefficients is given by $\frac{f(1) - f(-1)}{2}$.  It is clear that $f(1) = 1$ and note that 
$$f(-1) = \prod_{k=1}^n \frac{2k-1}{2k+1} = \frac{1}{2n+1}.$$
The overall probability is $\frac{n}{2n+1}$ as desired.
\end{proof}
\subsection{A3 - Algebra}
For each integer $m$, consider the polynomial $$P_m(x) = x^4 - (2m+4)x^2 + (m-2)^2.$$

For what values of $m$ is $P_m(x)$ the product of two non-constant polynomials with integer coefficients?

\begin{proof}
We claim that $m$ is the square of an integer or twice the square of an integer.  Set $y = x^2$.  We look for square-integer solutions for $y$.  From the quadratic formula,
\begin{align*}
y &= \frac{2m+4 \pm \sqrt{(2m+4) - 4(m-2)^2}}{2} \\
&= m+2 \pm \sqrt{(m+2)^2 - (m-2)^2 }\\
&= m+2 \pm \sqrt{4(2m)} \\
&= m + 2 \pm 2\sqrt{2m}\\
&= (\sqrt{m} \pm \sqrt{2})^2.
\end{align*}

Hence, $x = \pm \sqrt{m} \pm \sqrt{2}$.  Note that if $m$ is neither the square of an integer nor twice the square of an integer then the field $\Q(\sqrt{m}, \sqrt{2})$ is of degree $4$ and the Galois group acts transitively on the roots $\{\pm \sqrt{m} \pm \sqrt{2}\}$.  It follows that the polynomial is irreducible.

It is easy to verify that if $m$ is a square or twice a square, then $P_m(x)$ reduces into the product of non-constant integer polynomials.

%We must have $m = 2k^2$ for $k \in \Z$ in order for $y$ to be an integer.  It follows that 
%\begin{align*}
%y &= 2k+2 \pm 4k.
%\end{align*} 
%If $y = 2 - 2k$, then we must have $k = 0$ since $y \ge 0$ and $y$ must be a perfect square.  This gives a solution $m = 0$.
%
%If $y = 2 + 6k = 2(1+3k)$ we must have that $k$ is odd since $y$ is even and hence, must be divisible for $4$.  Thus, $k = 1 + 2\ell$ for $\ell \in \Z$.  This gives
%$$y = 2 (1 + 6\ell + 3) =4(2 + 3\ell).$$
%Taking the equation modulo $3$, we have
%$$y \equiv 1 \cdot 2 \equiv 2 \pmod{3},$$
%so it follows that $y$ cannot be a square since the quadratic residues of $3$ are $0$ and $1$.  
%
%Hence, we have the only possible solution $m = 0$.  It is easy to verify that 
%$$P_0(x) = x^4 - 4x^2 + 4 = (x^2 - 2)^2.$$
\end{proof}
\subsection{A4 - Geometry}
Triangle $ABC$ has area $1$.  Points $E, F, G$ lie on sides $BC$, $CA$, $AB$ such that $AE$ bisects $BF$ at point $R$, $BF$ bisects $CG$ at point $S$, and $CG$ bisects $AE$ at point $T$.  Find the area of the triangle $RST$.

\begin{proof}
We claim that $[RST] = \frac{7- \sqrt{5}}{4}.$
Let $EC/BC = r$, $FA/CA = s$, $GB/AB = t$.

Note that $[ABE] = [AFE]$ since they share a base $AE$ and $BR = FR$ implies that the share the same altitude length as well(drop altitudes from $F$ and $B$ and use the congruent triangles).  

Then, $[ABE] = [ABE]/[ABC]= BE/BC = 1 - EC/BC = 1-r$.  We also have $[ACE] = r$.  It follows that $[FCE] = [ACE] (FC/AC) = r(1-s)$.

Now,
$$1 = [ABC] = [ABE] + [AFE] + [EFC] = (1-r) + (1-r) + r(1-s) \Longrightarrow r(1+s) = 1.$$
Arguing similarly for the other sides, we have $s(1+t) = 1$, and $t(1+r) = 1$.  

It follows that 
$$r = \frac{1}{1+s} = \frac{1}{1 + \frac{1}{1+t}} = \frac{1}{1 + \frac{1}{1 + \frac{1}{r}}}.$$

Simplifying this, we find that $r = \frac{2+r}{3 + 2r}$, which gives $3r + 2r^2 = 2+ r$, or equivalently, $r^2 + r - 1 = 0$.  Plugging into the quadratic formula and taking the positive root gives
$$r =\frac{-1 + \sqrt{5}}{2},$$
and by repeating the argument, we have $r = s = t = \frac{-1 + \sqrt{5}}{2}$.  

Now, note that $[ATC] = [AEC] / 2 = r/2$, $[ATG] = [ACG] - [ATC] = 1 - t - r/2$.  Similarly, $[BSC] = t/2$ and $[BRE] = 1 - r - s/2$, so it follows that $[BRTG] = [ABE] - [ATG] - [BRE] = r/2 + s/2 + t - 1$.
\begin{align*}
[RST] &= [ABC] - [ACG] - [BSC] - [BRTG] \\
&= 1 - (1 - t) - (t/2) - (r/2 + s/2 + t - 1)\\
&= 1 - \frac{r + s + t}{2} \\
&= 1 - \frac{3\frac{\sqrt{5} - 1}{2}}{2} \\
&= \frac{7 - \sqrt{5}}{4}.
\end{align*}
\end{proof}
\begin{proof}
A brute-force calculation through vectors.  Define $A$ to be the origin and take $B, C$ to be basis vectors from $A$.  We can set $G = \beta B$, $F = (1 - \gamma) C$, $E = \alpha C + (1 - \alpha) C$.  Furthermore, we set $R = (1 - \rho) E$, $S = \sigma B + (1 - \sigma )F$, $T = \tau C + (1 - \tau) G$.  To satisfy the conditions of the problem, we must have that 
$$2R = B+F, 2S = C + G, 2T =  E.$$

After messy algebra, we obtain that 
$$\alpha = \frac{1 - \beta}{2 - \beta}, \beta = \frac{1 - \gamma}{2 - \gamma}, \gamma = \frac{1 - \gamma}{2 - \gamma},$$
which has an obvious solution $\alpha = \beta = \gamma = \frac{3 - \sqrt{5}}{2}$.  

It follows that 
$$(R-T, S- T) = \frac{1}{2}\begin{pmatrix} \alpha & 2\alpha - 1 \\ 1 - 2\alpha & 1 - \alpha \end{pmatrix},$$
so we can evaluate 
$$[RST] = \frac{[ABC]}{4} \begin{vmatrix}
 \alpha & 2\alpha - 1 \\ 1 - 2\alpha & 1 - \alpha
\end{vmatrix}  = \frac{\alpha^2}{2} = \frac{7 - 3\sqrt{5}}{4}.$$
\end{proof}
\subsection{A5 - Number Theory}
 Show that there are unique positive integers $a, n$ such that $a^{n+1} - (a+1)^n = 2001$.

\begin{proof}
We claim the unique pair of positive integers satisfying the claim is $(a, n) = (13, 2)$.  It is easy to verify that this is indeed a solution.  

Considering the equation in $\Z_3$, we see that $a \equiv 1 \pmod{3}$ - in the other cases, one of the terms vanishes and the other term is non-vanishing, so the difference cannot vanish.  

Considering the equation in $\Z_4$, we cannot have $a \equiv 0 \pmod{4}$, for the same reason as above.  If $a \equiv 1 \pmod{4}$, we must have that $n > 1$ in order for the equivalence to be satisfied.  If $a \equiv 2, 3 \pmod{4}$, we must have that $n$ is even.  

In the case with $a \equiv 1 \pmod{3}$ and $a \equiv 1 \pmod{4}$, we obtain $a \equiv 1 \pmod{12}$ and $n > 1$.   We see easily that $a = 1$ does not satisfy the equation for any $n > 1$.  For $a = 13$, we have a solution as above for $n = 2$.  It is easy to see that no higher value of $n$ also satisfies the equation since the function $f(x) = 13^{x + 1} - 14^x$ is monotonically increasing.   We can repeatedly apply similar arguments for the other cases to show that this is the unique solution.  
\end{proof}
\subsection{A6 - Calculus}
 Can an arc of a parabola inside a circle of radius $1$ have a length greater than $4$?

\begin{proof}
We claim that it is possible.  Take a unit circle given by $x^2 + (y-1)^2 = 1$ and a parabola $y = kx^2$.  The length of the curve inside the arc is given by 
$$L(k) = 2\int_0^{\sqrt{2k-1}/k} \sqrt{1 + 4k^2 x^2}\,dx = \frac{1}{4k} \int_0^{2\sqrt{2k-1}} \sqrt{1 + x^2} \,dx.$$

It is easy to show that $\sqrt{1 +  x^2} \ge \frac{1}{x+1}$ so it follows that $\lim_{k \to \infty} L(k) = +\infty$.  It follows that there exists some $k$ so that $L(k) > 4$ as desired.  
\end{proof}
\subsection{B1 - Combinatorics}
 Let $n$ be an even positive integer.  Write the numbers $1, 2, \dots, n^2$ in the squares of an $n \times n$ grid from left to right.  Color the squares of the grid so that half of the squares in each row and in each column are red and the other half are black.  Prove that for each coloring, the sum of the numbers on the red squares is equal to the sum of the numbers on the black squares.  

\begin{proof}
I have two proofs.  An outline of the first follows the approach of invariants.  Namely, we can start from a checkerboard pattern and repeatedly swap squares so that the sum of the numbers on the red squares is equal to the sum of the numbers on the black squares.  It suffices to show that the group of colorings with the given conditions is transitive under the transposition.  This is easy to show with an algorithm approach: for each square on a given board, we assign $1$ if it differs from the checkerboard, otherwise we assign $0$.  Then, we take the sum of the values.  We can choose transpositions so that the sum decreases on each turn, which must eventually terminate.  

The other approach is as follows.  For convenience, we subtract $1$ from each square so that it starts at $0$.  We can take the expansion in base $n$, so the value of each square $s$ is given by $nf(s) + g(s)$ where $0 \le f(s), g(s) < n$.  If we let $R$ denote the set of red numbers and $B$ the set of black numbers, note that $\sum_{s \in R} f(s) = \sum_{s \in B} f(s)$ since the number of red and black squares in each row is the same.  Similarly, $\sum_{s \in R} g(s) = \sum_{s \in B} g(s)$ since the number of red and black squares in each column is the same.  It follows that 
$$\sum_{s \in R} nf(s) + g(s) = \sum_{s \in B} nf(s) + g(s).$$
\end{proof}
\subsection{B2 - Algebra} 
Find all pairs $(x, y) \in \R^2$ satisfying the system
\begin{align*}
\frac{1}{x} + \frac{1}{2y} &= (x^2 + 3y^2)(3x^2 + y^2) \\
\frac{1}{x} - \frac{1}{2y} &= 2(y^4 - x^4).
\end{align*}

\begin{proof}
An easy algebra exercise.  Expanding the right-hand sides, then adding/subtracting the equations, we obtain $(x+y)^5 = 3$ and $(x - y)^5 = 1$ respectively.  This has a unique solution in $\R^2$, $\left(\frac{3^{1/5} + 1}{2}, \frac{3^{1/5} - 1}{2} \right)$.
\end{proof}
\subsection{B3 - Analysis} 
For any positive integer $n$, let $\<n\>$ denote the closest integer to $\sqrt{n}$.  Evaluate $\sum_{n=1}^\infty \frac{2^{\<n\>} + 2^{-\<n\>}}{2^n}$.

\begin{proof}
We reindex the sum by summing over the fixed values of $\<n\>$, which is non-decreasing.  Namely, we have 
$$\sum_{n=1}^\infty \frac{2^{\<n\>} + 2^{-\<n\>}}{2^n} = \sum_{m=1}^\infty \sum_{\<n\> = m}  \frac{2^{\<n\>} + 2^{-\<n\>}}{2^n} = \sum_{m=1}^\infty \left((2^m + 2^{-m})\sum_{\<n\> = m} 2^{-n}\right).$$

Note that $\<n\> = m$ whenever $n \in ((m-1/2)^2, (m+1/2)^2) = (m^2 - m+ 1/4, m^2 + m + 1/4)$.  This happens for $n \in [m^2 - m + 1, m^2 + m ]$.  Then, note that $$\sum_{n=m^2 - m + 1}^{m^2 + m} 2^{-n} = (1 - 2^{-m^2 - m}) - (1 - 2^{-m^2 + m}) = 2^{-m^2 + m} - 2^{-m^2 - m}.$$

Combining the results, we have 
\begin{align*}
\sum_{m=1}^\infty (2^{m} + 2^{-m}) (2^{-m^2 + m} - 2^{-m^2 - m}) &= \sum_{m=1}^\infty 2^{-m^2 + 2m} - 2^{-m^2 - 2m} \\
&= \sum_{m=1}^\infty 2^{-m(m-2)} - 2^{-m(m+2)} \\
&= \sum_{m=1}^\infty 2^{-m(m-2)} -  \sum_{m=3}^\infty 2^{-(m-2)m}  \\
&= 2^{1} + 2^{0} = 3.
\end{align*}
\end{proof}
\subsection{B4 - Number Theory}
 Let $S = \Q \setminus\{-1, 0, 1\}$.  Define $f: S \to S$ by $f(x) = x - 1/x$.  Prove or disprove that 
$$\bigcap_{n=1}^\infty f^{(n)}(S) = \emptyset.$$
\begin{proof}
The claim is true.  Suppose we had $x = \frac{p}{q} \in \bigcap_{n=1}^\infty f^{(n)}(S)$, where $(p, q) = 1$.  Then, there is some $m \in \N$ so that $f^{(m)}(x) = x$.  However, note that 
$$f\left(\frac{p}{q} \right) = \frac{p^2 - q^2}{pq},$$
and $|pq| > |q|$ since $p \not \in \{-1, 0, 1\}$.  Furthermore, note that $(p^2 - q^2, pq) = 1$.  If there is some prime $r$ diving both $p^2 - q^2$ and $pq$, then we have that $r$ divides one of $p-q, p+q$ and one of $p, q$.  However, from these we could conclude that $r$ divides both $p, q$ which contradicts the fact that $(p, q) = 1$.  It follows that since the denominators strictly increase, we cannot have $f^{(m)}(x) = x$.
\end{proof}
\subsection{B5 - Algebra}
let $a, b \in (0, 1/2)$ and let $g$ be a continuous real-valued function such that $g(g(x)) = ag(x) + bx$ for all real $x$.  Prove that $g(x) = cx$ for some constant $c$.
\begin{proof}
First, note that $g$ is injective.  This is because $g(x) = g(y)$ implies that $g(g(x)) = g(g(y))$, which implies that $ag(x) + bx = ag(y) + by$, which implies that $x = y$.   Since $g$ is continuous and injective, it follows that $g$ is monotone. 

We claim that $g$ is unbounded, which implies that it is surjective.  Suppose $|g(x)| \le M$ for all $x \in \R$.  Then, 
$$(a+1)M \ge |g(g(x)) - ag(x)| = |bx|,$$
which is a contradiction since $bx$ is unbounded.  

Now, let $x_0 \in \R$ be arbitrary and define $x_{n+1} = g(x_n)$, $x_{n-1} = g^{-1}(x_n)$.  The original functional equation gives a linear recurrence relation
$$x_{n+2} = ax_{n+1} + bx_n.$$
The corresponding characteristic polynomial is $\lambda^2 - a\lambda - b$, which has two distinct roots $\lambda_{\pm} = \frac{a \pm \sqrt{a^2 + 4b}}{2}$, since $a, b \in (0, 1/2)$.   It follows that 
$$x_n = c_+ \lambda_+^n + c_- \lambda_-^n$$
for constants $c_+, c_-$.

Note that $\lambda_+ > 0, \lambda_- < 0$ and $1 > |\lambda_+| > |\lambda_-|$.  

Suppose $f$ is monotone increasing(the case where $f$ is monotone decreasing is similar).  If $c_- \ne 0$ then as $n$ gets sufficiently small, $\lambda_-^n$ dominates $\lambda_+^n$, so there is some large enough $n$ so that $0 < x_n < x_{n+2}$ and $x_{n+3} < x_{n+1} < 0$, which would give that $g(x_n) > g(x_{n+2})$, a contradiction.  It follows that $c_- = 0$, so we have $x_0 = c_+$ and $g(x_0) = x_1 =  c_+ \lambda_+ = \lambda_+ x_0$, which gives the result.  
\end{proof}
\subsection{B6 - Algebra/Combinatorics}
Assume $(a_n)_{n \ge 1}$ is an increasing sequence of positive real numbers such that $\lim a_n/n = 0$.  Must there exist infinitely many positive integers $n$ such that $a_{n-i} + a_{n+i} < 2a_n$ for $i = 1, 2, \dots, n-1$? 

%%\begin{proof}
%Let $A = \operatorname{Conv}\{(n, a_n): n \in \N\}$, and let $\partial A$ denote the set of points of $A$ that are on the boundary of the convex hull.  If $a_n \in \partial A$, there there exists some positive slope $m > 0$ so that the line through $a_n$ with slope $m$ is above all the other points of $A$.  In other words,
%$$a_k \le a_n + m(k-n),$$
%with equality at $k = n$.
%Furthermore, since $\frac{a_k}{k} \to 0$, we have that 
%$$\frac{a_k - a_n}{k-n} \to 0,$$
%and $\frac{a_k - a_n}{k-n} \le m$ for all $k$ so it follows that it attains a maximum for some $k = r$.
%\end{proof}
\begin{proof}
Let $A = \operatorname{Conv}\{(n, a_n) : n \in \N\}$ and let $\partial A$ denote the set of points on the boundary of the convex hull.  

We claim that $\partial A$ contains infinitely many elements.  Suppose not.  Then, $\partial A$ has a last point $(N, a_N)$.  If we let $m = \sup_{n > N} \frac{a_n - a_N}{n - N}$, the slope of the line between $(N, a_N)$ and $(n, a_n)$, then the line through $(N, a_N)$ with slope $m$ lies above(or contains) each point $(n, a_n)$ for $n > N$.  However, since $a_n/n \to 0$ and $a_N, N$ are fixed, we have that $$\frac{a_n - a_N}{n - N} \to 0.$$
This implies that the set of slopes attains a maximum, i. e. there is some point $(M, a_M)$ with $M > N$ so that $m = \frac{a_M - a_N}{M - N}$.  But then, we must also have that $(M, a_M) \in \partial A$, contradicting the fact that $(N, a_N)$ is the last point in $\partial A$.

For each point on the boundary $(n, a_n) \in \partial A$, we must have that midpoint of the line through $(n-i, a_{n-i})$ and $(n+i, a_{n+i})$ for $i \in [n-1]$ must lie below $(n, a_n)$.  From this, it follows that $a_n > \frac{a_{n-i} + a_{n+i}}{2}$, which implies the result.  
\end{proof}
\pagebreak
\section{Putnam - 2002}
\subsection{A1 - Algebra}
Let $k \in \N$.  The $n$-th derivative of $1/(x^{k}-1)$ has the form $P_n(x)/(x^{k}-1)^{n+1}$ where $P_n(x)$ is a polynomial.  Find $P_n(1)$.
\begin{proof}
We can write 
\begin{align*}
\frac{P_{n}(x)}{(x^k-1)^{n+1}} &= \frac{d}{dx} \left( \frac{P_{n-1}(x)}{(x^k - 1)^n}\right) \\
&= \frac{(x^k - 1)^n P_{n-1}'(x) - nkx^{k-1}(x^k - 1)^{n-1} P_{n-1}(x)}{(x^k - 1)^{2n}} \\
\Longrightarrow P_n(x) &= (x^k -1)P_{n-1}'(x) - nkx^{k-1}P_{n-1}(x).
\end{align*}

Plugging in $x = 1$ gives a recurrence relation $P_n(1) = -nk P_{n-1}(x)$.  It follows that $$P_n(1) = n!(-k)^n P_0(x) = n!(-k)^n.$$

\end{proof}
\subsubsection{Official Solution}
An alternate solution comes from expanding $\frac{1}{x^k - 1}$ in a Laurent series around $1$.  
\begin{proof}
It suffices to keep track of the $O((x-1)^{-1})$ terms since the others vanish upon plugging in $1$.

Note that 
$$\frac{1}{x^k - 1} = \frac{1}{k(x-1) + \dots} = \frac{1}{k} (x-1)^{-1} + \dots.$$
Taking the $n$-th, derivative, we have obtain 
$$\frac{d^n}{dx^n} \frac{1}{x^k - 1} = \frac{(-1)^n n!}{k(x-1)^{-n-1}} + \dots.$$
It follows that 
\begin{align*}
P_n(x) &= (x^k - 1)^{n + 1} \frac{d^n}{dx^n} \frac{1}{x^k - 1} \\
&= (k(x-1) + \dots)^{n+1} \left(\frac{(-1)^n n!}{k(x-1)^{-n-1}} + \dots \right) \\
&= k^n (-1)^n n! + \dots.
\end{align*}
\end{proof}

\subsection{A2 - Combinatorics}
Given any five points on a sphere, show that some four of them must lie on a closed hemisphere.  
\begin{proof}
Draw a great circle through any two points and consider the remaining three.  By the pigeonhole principle, there is closed hemisphere with at least two points, and choosing this hemisphere gives the result.  
\end{proof}

\subsection{A3 - Combinatorics}
Let $n \ge 2$ be an integer and $T_n$ the number of nonempty subsets $S$ of $\{1, 2, \dots, n\}$ with the property that the average of the elements of $S$ is an integer.  Prove that $T_n - n$ is always even.  
\begin{proof}
Note that each one element subset $\{1\}, \{2\}, \dots, \{n\}$ has the property that the average of the element is an integer.  It suffices to consider the subsets at least $2$ elements.  For set of size at least $2$, we can pair them into $(S, S \cup\{a\})$, where $a \not \in S$ and the average of the elements in $S$ is $a$.  Each subset is contained in exactly one pair, so each of them don't contribute to the parity of $T_n - n$.  It follows that $T_n - n$ is even as desired.  
\end{proof}

\subsection{A4 - Combinatorics}
in Determinant Tic-Tac-Toe, Player 1 enters a 1 in an empty $3 \times 3$ matrix.  Player $0$ counters with a $0$ in a vacant position, and play continues in turn until the matrix is completed with five $1$'s and four $0$'s.  Player $0$ wins if the determinant is $0$ and player $1$ wins otherwise.  Who wins and how?
\begin{proof}
Player $0$ wins.  After exchanging rows and columns(which doesn't change the norm of the determinant), we can assume without loss of generality that player $1$ enters a $1$ in the $a_{11}$ square.  

In the optimal strategy, player $0$ enters a $0$ in the $a_{22}$ square.  There are 3 possible cases to check for player $1$'s next move:
\begin{enumerate}
\item $a_{12}$ or $a_{21}$,
\item $a_{13}$ or $a_{31}$,
\item $a_{23}$ or $a_{32}$,
\item $a_{33}$.
\end{enumerate}
For each of these cases, it suffices to check the first since we can exchange $a_{ij}$ with $a_{ji}$ in order to obtain the strategy in the other corresponding case.  Note that if player $0$ creates a row/column of $0$'s or a $2 \times 2$ block of $0$'s, the determinant of the matrix will be $0$.

(1) When player $1$ enters a $1$ in $a_{12}$, player $0$ enters a $0$ in square $a_{32}$. If player $1$ enters in $a_{21}$ or $a_{23}$, player $0$ enters in $a_{33}$ or $a_{31}$ respectively. In this position, player $1$ cannot stop player $0$ from creating a $2 \times 2$ block or a row of $0$'s.   Alternatively, if player $1$ enters in $a_{13}$, player $0$ enters in $a_{21}$.  In this position, player $1$ cannot stop player $0$ from creating a $2 \times 2$ block or a row of $0$'s.  In the other cases, we take a knight's move across whatever player $1$ plays and in this position, player $1$ cannot stop player $0$ from creating a $2 \times 2$ block or a row of $0$'s.

The other cases follow a similar analysis, creating a triangle block of $0$'s in other to create two threats.  
\end{proof} 
\subsection{A5 - Number Theory}

Define a sequence by $a_0 = 1$, together with the rules $a_{2n+1} = a_n$ and $a_{2n+2} = a_n + a_{n+1}$ for each integer $n \ge 0$.  Prove that every positive rational number appears in the set $\{a_n/a_{n+1}: n \ge 0\}$.

\begin{proof}
We proceed by induction on $k = \max\{p, q: \gcd(p, q) = 1\}$.  For $k = 1$, we know that $a_0 = a_1 = 1$ so we have $1/1$, which contains all the rational numbers $p/q$ with $\max\{p, q\} \le 1$.  Suppose the set contains all the rationals $p/q$ with $\max\{p, q: \gcd(p, q) = 1\} \le n$.  Then it contains $\frac{n+1-k}{k}$ for $1 \le k \le n$ whenever $\gcd(n+1-k, k) = 1$.  Note that $\gcd(n+1 - k, k) = 1 \Leftrightarrow \gcd(n+1, k) = 1$.

It follows that we have $a_m = \ell(n + 1 - k), a_{m+1} = \ell(k)$ for some $\ell \in \N$.  Then, $a_{2m+1} = \ell(n+1-k)$, $a_{2n+2} = \ell(n+1)$ and $a_{2n+3} = \ell(k)$.  It follows that the set contains 
$$\frac{n+1-k}{n+1}, \frac{n+1}{k}$$
for each $1 \le k\le n$ so that $\gcd(n+1, k) = 1$, which proves the inductive step.  
\end{proof}

\subsection{A6 - Analysis}
Fix an integer $b \ge 2$.  Let $f(1) = 1$, $f(2) = 2$, and for each $n \ge 3$, define $f(n) = nf(d)$, where $d$ is the number of base-$b$ digits of $n$.  For which values of $b$ does the sum $\sum_{n \ge 1} 1/f(n)$ converge?

\begin{proof}
The sum converges for $b = 2$ and diverges for $b \ge 3$.  

We first consider $b \ge 3$.  Suppose the sum converges.  Note that we can write 
$$\sum_{n = 1}^\infty \frac{1}{f(n)} = \sum_{d = 1}^\infty \frac{1}{f(d)}\sum_{n = b^{d-1}}^{b^{d} - 1} \frac{1}{n}.$$
Note that $\sum_{n = b^{d-1}}^{b^d - 1} \frac{1}{n}$ is a left-endpoint Riemann approximation for the integral $\int_{b^{d-1}}^{b^d} \frac{1}{x}$ and the function $\frac{1}{x}$ is monotonically decreasing on this interval so it follows that 
$$\sum_{n = b^{d-1}}^{b^d - 1} \frac{1}{n} > \int_{b^{d-1}}^{b^d} \frac{1}{x} = \log b.$$
However, this implies that 
$$\sum_{n = 1}^\infty \frac{1}{f(n)} > \log b \sum_{d = 1}^\infty \frac{1}{f(d)},$$
which is a contradiction since $\log b > 1$.


Now, we show that the sum converges in the case of $b = 2$.  Let $C = \log 2 + \frac{1}{8} < 1$.  We prove by induction that for each $m \in \N$, $$\sum_{n=1}^{2^{m} - 1} \frac{1}{f(m)} < 1 + \frac{1}{2} + \frac{1}{6(1-C)} = L.$$

For $m = 1, 2$, the result is clear.  Suppose it is true for all $m \in \{1, 2, \dots, N-1\}$.  Note that 
\begin{align*}
\sum_{n=1}^{2^N - 1} \frac{1}{f(n)} &= 1 + \frac{1}{2} + \frac{1}{6} + \sum_{d=3}^N \frac{1}{f(d)} \sum_{n = 2^{d - 1}}^{2^d - 1} \frac{1}{n}.
\end{align*}
Then, using a right-endpoint Riemann approximation, we have 
\begin{align*}
\sum_{n = 2^{d-1}}^{2^d - 1} \frac{1}{n} &= \frac{1}{2^{d - 1}} - \frac{1}{2^{d}} + \sum_{n = 2^{d-1}+1}^{2^d} \frac{1}{n} \\
&< 2^{-d} + \int_{2^{d-1}}^{2^d} \frac{dx}{x} \\
&< \frac{1}{8} + \log 2 = C.
\end{align*}
It follows that 
\begin{align}
1 + \frac{1}{2} + \frac{1}{6} + \sum_{d=3}^N \frac{1}{f(d)} &< 1 + \frac{1}{2} + \frac{1}{6} + C \sum_{d = 3}^N \frac{1}{ f(d)} \\
&< 1 + \frac{1}{2} + \frac{1}{6} + \frac{C}{6(1 - C)} \\
&= 1 + \frac{1}{2} + \frac{1}{6(1-C)} = L,
\end{align}
where we used the strong induction hypothesis to obtain $(2)$.
\end{proof}
\subsection{B1 - Probability}
Shanille shoots free throws on a basketball court.  She hits the first and misses the second, and thereafter the probability that she hits the next shot is equal to the proportion of shots she has hit so far.  what is the probability she hits exactly $50$ of her first $100$ shots?
\begin{proof}
We claim the probability of hitting exactly $k$ shots after $n$ throws for $k \in \{1, \dots, n-1\}$is $\frac{1}{n-1}$.  For $n = 2$, this is clear.  If we suppose the result is true for $n = m$, the probability of making $k$ shots after $m + 1$ throws is 
$$\frac{k-1}{m} \cdot \frac{1}{m-1} + \frac{m - k}{m} \cdot \frac{1}{m-1} = \frac{m-1}{m(m-1)} = \frac{1}{m},$$
which proves the inductive hypothesis.  

\end{proof}

\subsection{B2 - Combinatorics}
Consider a polyhedron with at least five faces such that exactly three edges emerge from each of its vertices. Two players play the following game: Each, in turn, signs his or her name on a previously unsigned face. The winner is the player who first succeeds in signing three faces that share a common vertex. Show that the player who signs first will always win by playing as well as possible.
\begin{proof}
First, we claim that any such polyhedron has a face with at least $4$ edges.  The proof is as follows.  Let $V, E, F$ denote the number of vertices, edges, and faces respectively.  For sake of contradiction, suppose that each face has exactly $3$ edges.  We can count the number of edges by counting $3$ edges for each face, but dividing by $2$ since each edge connects exactly $2$ faces.  It follows that $E = \frac{3F}{2}$.  Similarly, $V = \frac{2E}{3} = F$, since we can count two vertices for each edge, but dividing by $3$ since each vertex has exactly $3$ outgoing edges.  By Euler's formula, we have 
$$2 = V - E + F = 2F - \frac{3F}{2} = \frac{F}{2} \Longrightarrow F = 4,$$
which is a contradiction since $F \ge 5$.  

Now, take the face with at least $4$ edges, call it $F_0$.  Player $1$ signs in $F_0$.  If player $2$ does not sign in a face adjacent to $F_0$, then player $1$ can sign in any face adjacent to $F_0$.  At this point, player $2$ cannot stop player $1$ from signing three faces that share a common vertex since there are two threats.  Hence, we can suppose player $2$ does sign in a face adjacent to $F_0$, call it $F_1$.  Since the face has at least $4$ edges, we can sign in a square adjacent to $F_0$ that is not adjacent to $F_1$.  at this point, player $2$ cannot stop player $1$ from signing three faces that share a common vertex since there are two threats.  
\end{proof}
\subsection{B3 - Analysis}
Show that for $n > 1$,
$$\frac{1}{2ne} < \frac{1}{e} - \left( 1 - \frac{1}{n} \right)^n < \frac{1}{ne}. $$
\begin{proof}
Multiplying by $e$ and subtracting from $1$, we have 
$$1 - \frac{1}{n} < e \left(1 - \frac{1}{n}\right)^n < 1 - \frac{1}{2n}.$$
Taking the logarithm(which is monotonically increasing), we equivalently have
$$\log(1 - 1/n) < 1 + n\log(1 - 1/n) < \log(1- 1/(2n)).$$
Finally, noting the Taylor series expansion of $\log(1 + x) = -\sum_{k \ge 1} \frac{(-x)^k}{k}$(which converges for $x \in (-1, 1)$), we have
$$-\sum_{k \ge 1} \frac{1}{kn^k}< 1 - n\sum_{k \ge 1} \frac{1}{kn^k} < -\sum_{k \ge 1} \frac{1}{k(2n)^k}$$
or equivalently
$$\sum_{k\ge 1}\frac{1}{k(2n)^k} < \sum_{k \ge 1} \frac{1}{(k + 1)n^k} <\sum_{k \ge 1} \frac{1}{kn^k},$$
which is evidently true since $k2^k > k + 1$ and $k+1 > k$ for $k \ge 1$.
\end{proof}
\subsection{B4 - Combinatorics}
An integer $n$, unknown to you, has been randomly chosen in the interval $[1,2002]$ with uniform probability. Your objective is to select $n$ in an odd number of guess. After each incorrect guess, you are informed whether $n$ is higher or lower, and you $\textbf{must}$ guess an integer on your next turn among the numbers that are still feasibly correct. Show that you have a strategy so that the chance of winning is greater than $\tfrac{2}{3}$.

\begin{proof}
Guess the sequence of numbers $1, 3, 4, 6, 7, \dots$ alternating between $x \equiv 1 \pmod{3}$ and $x \equiv 1 \pmod{3}$.  If the chosen integer is  $1 \pmod{3}$, then it will be chosen in an odd turn.  If the chosen integer is $0 \pmod{3}$, then it will be chosen in an even turn.  Otherwise, it is $n \equiv 2 \pmod{3}$ so it will be chosen immediately after $n+1$ is chosen, which happens after an even turn, so it is an odd turn.  This gives a chance of winning of at least $2/3$ as desired.  
\end{proof}
\subsection{B5 - Number Theory}
A palindrome in base $b$ is a positive integer whose base-$b$ digits read the same backwards and forwards; for example, $2002$ is a $4$-digit palindrome in base $10$. Note that $200$ is not a palindrome in base $10$, but it is a $3$-digit palindrome: $242$ in base $9$, and $404$ in base $7$. Prove that there is an integer which is a $3$-digit palindrome in base $b$ for at least $2002$ different values of $b$.
\begin{proof}
Let $N = 2002!$.  We claim that $N^2$ is a $3$-digit palindrome in base $b_d = \frac{N}{d} - 1$ for each $d \in \{1, 2, \dots, 2002\}$.  Note that $2d^2 < \frac{2002!}{d} - 1$ for each $d \in \{1, 2, \dots, 2002\}$.  It follows that we can write
\begin{align*}
([d^2][2d^2][d^2])_{b_d} &= d^2\left(\frac{N}{d} - 1 \right)^2 + 2d^2\left(\frac{N}{d} - 1 \right) + d^2 \\
&= N^2 - 2Nd - d^2 + 2Nd - 2d^2 + d^2 \\
&= N^2.
\end{align*}

\end{proof}
\subsection{B6 - Number Theory}
Let $p$ be a prime number. Prove that the determinant of the matrix\[ \begin{bmatrix}x & y & z\\ x^p & y^p & z^p \\ x^{p^2} & y^{p^2} & z^{p^2} \end{bmatrix} \]is congruent modulo $p$ to a product of polynomials of the form $ax+by+cz$, where $a$, $b$, and $c$ are integers. (We say two integer polynomials are congruent modulo $p$ if corresponding coefficients are congruent modulo $p$.)
\begin{proof}
Note that the determinant $$P(x, y, z) = \sum_{\text{cyc}}x(y^pz^{p^2} - z^py^{p^2}),$$
which is a polynomial of degree $p^2 + p + 1$ in $x, y, z$.

Suppose not all of $a, b, c$ are zero.  Without loss of generality, $a \ne 0$.  Note that 
\begin{align*}
aP(x, y, z) &= \begin{vmatrix}
ax & y & z\\ ax^p & y^p & z^p \\ ax^{p^2} & y^{p^2} & z^{p^2}
\end{vmatrix} \\
&=  \begin{vmatrix}
ax +by + cz & y & z\\ ax^p +by^p + cz^p & y^p & z^p \\ ax^{p^2} +by^{p^2} + cz^{p^2} & y^{p^2} & z^{p^2}
\end{vmatrix} \\
&=  \begin{vmatrix}
ax +by + cz & y & z\\ a^px^p +b^py^p + c^pz^p & y^p & z^p \\ a^{p^2}x^{p^2} +b^{p^2}y^{p^2} + c^{p^2}z^{p^2} & y^{p^2} & z^{p^2}
\end{vmatrix} \\
&= \begin{vmatrix}
ax +by + cz & y & z\\ (ax +by + cz )^p & y^p & z^p \\ (ax +by + cz )^{p^2} & y^{p^2} & z^{p^2}
\end{vmatrix} \\
&= (ax+by+cz) \begin{vmatrix}
1 & y & z\\ (ax +by + cz )^{p-1} & y^p & z^p \\ (ax +by + cz )^{p^2-1} & y^{p^2} & z^{p^2}
\end{vmatrix} \\
\end{align*}
It follows that $P(x, y, z)$ divides $(ax+by+cz)$ whenever $a, b, c$ are not all zero in $\Z/p\Z$.  This includes $\frac{p^3 - 1}{p-1} = p^2 + p + 1$ terms(where we divide $p-1$ to account for scaling), which is exactly the degree of the polynomial.  Since $\Z/p\Z$ is a field, it is a unique factorization domain, so it follows that $P(x,  y, z)$ is exactly the product of $ax+by+cz$ for each  $a, b, c$ not all zero in $\Z/p\Z$(up to some constant), which proves the result.  
\end{proof}
\pagebreak

\section{Putnam 2003}
\subsection{A1 - Combinatorics}
Let $n$ be a fixed positive integer. How many ways are there to write $n$ as a sum of positive integers,
\[n = a_1 + a_2 + \cdots a_k\]with $k$ an arbitrary positive integer and $a_1 \le a_2 \le \cdots \le a_k \le a_1 + 1$? For example, with $n = 4$, there are four ways: $4$, $2 + 2$, $1 + 1 + 2$, $1 + 1 + 1 + 1$.
\begin{proof}
We claim that for each fixed positive integer $n$, there are exactly $n$ ways to write it as a sum of positive integers satisfying the above conditions.  We can prove this by induction on $n$  For $m = 1$, the result is clear.  Suppose it is true for $n = k$.  It suffices to prove the result for $n = k+1$.  By the inductive hypothesis, we can write $k = a_1 + a_2 + \dots + a_{\ell}$ in $k$ ways.  For each combination, note that if we take $b_\ell =  a_1 + 1$ and $b_j = a_{j+1}$ for $1 \le j \le \ell-1$, then 
$$k+1 = 1 + a_1 + \dots + a_\ell = b_1 + b_2 + \dots + b_{\ell}$$
is a valid combination for $k+1$.  There is exactly one indistinguishable way to group the extra $1$ since grouping with another $a_j = a_1$ is indistinguishable and if we group with $a_j = a_1 + 1$, then the overall sum does not satisfy the condition that the last term is bounded by one more than the first term.  Hence, we have exactly $k$ sums of the above form.  We have exactly one additional combination given by the sum of $k+1$ $1$'s, which is a total of $k+1$ ways, as desired.  

\end{proof}
\subsection{A2 - Algebra}
Let $a_1, a_2, \cdots , a_n$ and $b_1, b_2,\cdots, b_n$ be nonnegative real numbers. Show that\[(a_1a_2 \cdots a_n)^{1/n}+ (b_1b_2 \cdots b_n)^{1/n} \le ((a_1 + b_1)(a_2 + b_2) \cdots (a_n + b_n))^{1/n}\]
\begin{proof}
This is a direct application of Holder's Inequality.  
\end{proof}
\subsubsection{Alternate Solution}
\begin{proof}
Note that 
\begin{align*}
\left (\frac{\prod_{k=1}^n a_k}{\prod_{k=1}^{n} (a_k + b_k)} \right)^{1/n} + \left (\frac{\prod_{k=1}^n b_k}{\prod_{k=1}^{n} (a_k + b_k)} \right)^{1/n} &= \left (\prod_{k=1}^n \frac{a_k}{a_k + b_k} \right)^{1/n} + \left (\prod_{k=1}^n \frac{b_k}{a_k + b_k} \right)^{1/n}  \\
&\le \frac{1}{n} \sum_{k=1}^n \frac{a_k}{a_k+b_k} + \frac{1}{n} \sum_{k=1}^n \frac{b_k}{a_k + b_k} \\
&= \frac{1}{n} \sum_{k=1}^n \frac{a_k + b_k}{a_k + b_k} \\
&= \frac{1}{n} \sum_{k=1}^n 1 = 1.  
\end{align*}
Multiplying both sides of the inequality by $\prod_{k=1}^n (a_k+b_k)^{1/n}$ gives the desired result.  
\end{proof}

\subsection{A3 - Calculus}
Find the minimum value of\[|\sin{x} + \cos{x} + \tan{x} + \cot{x} + \sec{x} + \csc{x}|\]for real numbers $x$.
\begin{proof}
We claim the minimum value is given by $2\sqrt{2} - 1$.  Let $y = \pi/4 - x$.  Note that $$\sin{x} + \cos{x} = \sqrt{2} \cos(\pi/4 - x) = \sqrt{2} \cos y,$$
$$\sin{x} \cos{x} = \frac{1}{2} \sin(2x) = \frac{1}{2} \cos(\pi/4 - 2x) = \frac{1}{2} \cos{2y} = \cos^2 y - \frac{1}{2}.$$

Let $u = \sqrt{2} \cos y$.  
\begin{align*}
\sin x + \cos x + \tan x + \cot x + \sec x + \csc x &= \sin x + \cos x + \frac{1}{\sin x \cos x} + \frac{\sin x + \cos x}{\sin x \cos x} \\
&= u + \frac{2}{u^2 - 1} + \frac{2u}{u^2 - 1} \\
&= u + \frac{2(u + 1)}{u^2 - 1}.
\end{align*}
We wish to find the minimum value of $|f(u)|$ where $f(u) =  u + \frac{2(u + 1)}{u^2 - 1} $ and $u \in [-\sqrt{2}, \sqrt{2}]$.  Note that at for $u = -1$, the possible values of $y$ are $5\pi/4$ and $7\pi/4$.  At these values, the desired expression takes the values $2$ and $2 + \sqrt{2}$ respectively.  Assuming $u \ne 1$, we can write $f(u) = u + \frac{2}{u-1}$.  

Note that $$f(\sqrt{2}) = \sqrt{2} + \frac{2}{\sqrt{2} - 1} = \frac{4 - \sqrt{2}}{\sqrt{2} - 1} = 2 + 3\sqrt{2},$$
$$f(-\sqrt{2}) = -\sqrt{2} - \frac{2}{\sqrt{2} + 1} = -\frac{4 + \sqrt{2}}{\sqrt{2} + 1} = 3\sqrt{2} - 2.$$

Furthermore, $$f'(u) = 1 - \frac{2}{(u - 1)^2},$$
which has critical points at $u = 1 \pm \sqrt{2}$, but $1 + \sqrt{2}$ is outside of $[-\sqrt{2}, \sqrt{2}]$, so it suffices to check $u_0 = 1 - \sqrt{2}$.

At this point $$f(u_0) = 1 - \sqrt{2 } - \frac{2}{ \sqrt{2}} = 1 - 2\sqrt{2}.$$

Comparing all the critical values using the approximation $\sqrt{2} = 1.41 + O(|.01|)$, we find that the minimum possible value of $|f(u)|$ is given by $2\sqrt{2} - 1$.

\end{proof}
\pagebreak
\subsection{A4 - Algebra}
Suppose that $a, b, c, A, B, C$ are real numbers, $a \not= 0$ and $A \not= 0$, such that\[|ax^2+ bx + c| \le |Ax^2+ Bx + C|\]for all real numbers $x$. Show that\[|b^2- 4ac| \le |B^2- 4AC|\]
\begin{proof}
First, note that we must have that $|a| \le |A|$ which we can show by taking the limit in the given expression.  Let $\delta = b^2 - 4ac$, $\Delta = B^2 - 4AC$.  We can also define $p(x) = ax^2 + bx + c$ and $P(x) = Ax^2 + Bx + C$.  
%Note that $$ax^2 +bx + c = a\left(x - \frac{b}{2a}\right)^2 - \left (\frac{b^2 - 4ac}{4a} \right).$$
We proceed by cases on the sign on $\Delta$.
\begin{itemize}
\item Case 1: $\Delta > 0$.

In this case, we have that $P(x) = A(x-r_1)(x - r_2)$ for $r_1, r_2 \in \R$.  Then, we have that $|p(r_1)| \le |P(r_1)| = 0$ and $|p(r_2)| \le |P(r_2)| = 0$ so it follows that $p(x) = a(x-r_1)(x-r_2)$.  Since both polynomials have the same roots, it follows that $\frac{\sqrt{\delta}}{a} = \frac{\sqrt{\Delta}}{A}$, which is exactly the distance between $r_1$ and $r_2$.  It follows that 
$$|\delta| \le \frac{|a|^2}{|A|^2} |\Delta| \le |\Delta|.$$
\item Case 2: $\Delta = 0$.

In this case, we have that $P(x) = A(x-r)^2$ for $r \in \R$.  As before, we have that $p(r) = 0$.  Suppose that $p(x) = a(x-r)(x-s)$ for some $s \in \R$.  Note that we also have $P'(r) = 0$ since this is the vertex of the parabola.  If $s \ne r$, then we must have that $|p'(r)| > 0$ since $r$ is not the vertex.  It follows that the graphs of $|p(x)|$ and $|P(x)|$ intersect in the interval $[s, r]$(or $[r, s]$ depending on $r$), which is a contradiction.  It follows that $p(x) = a(x-r)^2$. Hence, $\delta = \Delta = 0$.

\item Case 3: $\Delta < 0$.  

In this case, we have that $P(x) = A(x-Z_1)(x-Z_2)$ for $Z_1, Z_2 \in \C$.  Note that $|P(x)|$ is minimized at $Z_* = \frac{Z_1+Z_2}{2}$.  Suppose that $p(x) = a(x - z_1)(x - z_2)$ and let $z_* = \frac{z_1+z_2}{2}$.  We have that 
$$\frac{|A(Z_1 - Z_2)^2|}{4} =  |P(Z_*)| \ge |P(z_*)| \ge |p(z_*)| = \frac{|a(z_1 - z_2)^2|}{4},$$
so it follows that $|z_1 - z_2| \ge |Z_1 -  Z_2|$ which proves that $|\delta| \le |\Delta|$ using the same method as in Case $1$.  
\end{itemize}


\end{proof}
\pagebreak
\subsection{A5 - Combinatorics}
A Dyck $n$-path is a lattice path of $n$ upsteps $(1, 1)$ and $n$ downsteps $(1, -1)$ that starts at the origin $O$ and never dips below the $x$-axis. A return is a maximal sequence of contiguous downsteps that terminates on the $x$-axis. For example, the Dyck $5$-path illustrated has two returns, of length $3$ and $1$ respectively. Show that there is a one-to-one correspondence between the Dyck $n$-paths with no return of even length and the Dyck $(n - 1)$ paths.

\[\begin{picture}(165,70)
\put(-5,0){O}
\put(0,10){\line(1,0){150}}
\put(0,10){\line(1,1){30}}
\put(30,40){\line(1,-1){15}}
\put(45,25){\line(1,1){30}}
\put(75,55){\line(1,-1){45}}
\put(120,10){\line(1,1){15}}
\put(135,25){\line(1,-1){15}}
\put(0,10){\circle{1}}\put(0,10){\circle{2}}\put(0,10){\circle{3}}\put(0,10){\circle{4}}
\put(15,25){\circle{1}}\put(15,25){\circle{2}}\put(15,25){\circle{3}}\put(15,25){\circle{4}}
\put(30,40){\circle{1}}\put(30,40){\circle{2}}\put(30,40){\circle{3}}\put(30,40){\circle{4}}
\put(45,25){\circle{1}}\put(45,25){\circle{2}}\put(45,25){\circle{3}}\put(45,25){\circle{4}}
\put(60,40){\circle{1}}\put(60,40){\circle{2}}\put(60,40){\circle{3}}\put(60,40){\circle{4}}
\put(75,55){\circle{1}}\put(75,55){\circle{2}}\put(75,55){\circle{3}}\put(75,55){\circle{4}}
\put(90,40){\circle{1}}\put(90,40){\circle{2}}\put(90,40){\circle{3}}\put(90,40){\circle{4}}
\put(105,25){\circle{1}}\put(105,25){\circle{2}}\put(105,25){\circle{3}}\put(105,25){\circle{4}}
\put(120,10){\circle{1}}\put(120,10){\circle{2}}\put(120,10){\circle{3}}\put(120,10){\circle{4}}
\put(135,25){\circle{1}}\put(135,25){\circle{2}}\put(135,25){\circle{3}}\put(135,25){\circle{4}}
\put(150,10){\circle{1}}\put(150,10){\circle{2}}\put(150,10){\circle{3}}\put(150,10){\circle{4}}
\end{picture}\]
\begin{proof}
Let $D_{n-1}$ be the set of $(n-1)$-Dyck paths and let $O_{n}$ ne the set of $n$-Dyck paths with no return of even length.  We can define functions $f: D_{n-1} \to O_n$ and $g: O_n \to D_{n-1}$ with $f \circ g = \id_{O_n}$ and $g \circ f = \id_{D_{n-1}}$.

We define $f$ as follows.  Let $p = a_1a_2\dots a_{2n-2} \in D_{n-1}$.  If $p$ has no return of even length, we can construct a path $f(p) = (1, 1)(1, -1)p \in O_n$.  Otherwise, suppose $p$ has at least one return of even length.  Suppose that $a_i \dots a_j$ is the last return of even length in $p$.  Then, we can define $f(p) = (1, 1) a_1 \dots a_i \dots a_j (1, -1) a_{j+1} \dots a_{2n-2}$.  This is in $O_n$ because the operation $f(p)$ removes all the returns before the last return of even length, which we extend to a return of odd length.  

Next, we define $g$.  Let $p = a_1a_2\dots a_{2n} \in O_n$.  Suppose $a_i \dots a_j$ is the first return of $p$.  We can define $f(p) = a_2 \dots a_i \dots a_{j-1} a_{j+1} \dots a_{2n}$.  This is in $D_{n-1}$ because $a_1 = (1, 1)$ and $a_j = (1, -1)$, so the remaining path remains above $0$ at all times.  

It is easy to verify that these functions satisfy the desired condition which gives the desired $1-1$ correspondence.  
\end{proof}
\pagebreak
\subsection{A6 - Combinatorics}
	For a set $S$ of nonnegative integers, let $r_S(n)$ denote the number of ordered pairs $(s_1, s_2)$ such that $s_1 \in S$, $s_2 \in S$, $s_1 \neq s_2$, and $s_1 + s_2 = n$. Is it possible to partition the nonnegative integers into two sets $A$ and $B$ in such a way that $r_A(n) = r_B(n)$ for all $n$?
\begin{proof}
WLOG suppose $1 \in A$, $0 \in B$.  Define $f(x) = \sum_{n \in A} x^n$,  $g(x) = \sum_{n \in B} x^n$ with $|x| < 1$.  Note that $f(x) + g(x) = \sum_{n=0}^\infty x^n = \frac{1}{1-x}$.  Furthermore, note that 
$$r_A(n) = [x^n] (f(x^2) - f(x)^2), r_B(n) = [x^n] (g(x^2) - g(x)^2),$$
where $[x^n](\cdot)$ denotes the $n$-th coefficient of the power series $\cdot$.  

We wish to show that there exists a choice $A \sqcup B = \N$ so that $f(x^2) - f(x)^2 = g(x^2) - g(x)^2$.  Equivalently, we have 
$$\frac{f(x) - g(x)}{f(x^2) - g(x)^2} = \frac{1}{f(x) + g(x)} = 1 - x,$$
and replacing $x \to x^{2^k}$ we obtain
$$\frac{f(x^{2^k}) - g(x^{2^k})}{f(x^{2^{k+1}} ) - g(x^{2^{k+1}})} = 1-x^{2^{k}}.$$

Taking the product of successive terms gives a telescoping product
$$f(x) - g(x) = \left(\prod_{k=0}^{n-1} (1 - x^{2^k}) \right) (f(x^{2^{n + 1}} ) - g(x^{2^{n+1}})).$$
Taking the limit as $n \to \infty$ and noting that $f(0) = 1$, $g(0) = 0$ by assumption, we have 
$$f(x) - g(x) = \prod_{k=0}^\infty (1 - x^{2^k}).$$

Furthermore, if we let $s_j = 0$ if $j \in A$, $s_j =1$ if $j \in B$, then we have 
$$f(x) - g(x) = \sum_{n=0}^\infty (-1)^{s_n} x^n = \prod_{k=0}^{\infty} (1-x^{2^k}).$$

The positive terms in the product correspond to an even number of terms, or equivalently the integers $n$ where the sum of the digits in the binary expansion is even.  It follows that taking $A$ to be the integers where the sum of the digits in the binary expansion is even and $B$ the integers where the sum of the digits in the binary expansion is odd satisfies the problem statement.
\end{proof}
\pagebreak
\subsection{B1 - Algebra}
Do there exist polynomials $a(x)$, $b(x)$, $c(y)$, $d(y)$ such that\[1 + xy + x^2y^2= a(x)c(y) + b(x)d(y)\]holds identically?
\begin{proof}
We claim no such polynomials exist.  
For a polynomial $P(x, y) = \sum_{i=0}^n \sum_{j=0}^n a_{ij} x^i y^j$ where $n$ is the degree of $P$, we can alternatively represent it with the matrix $A = (a_{ij})$.  Let $n = \max (\deg a, \deg b, \deg c, \deg y)$.  Note that $1 + xy + x^2y^2$ corresponds to the $n \times n$ matrix $P = (p_{ij})$ with $p_{11} = p_{22} =p_{33} = 1$ and $p_{ij} = 0$ for all other entries.  We can represent $a(x), b(x), c(y), d(y)$ with column and row vectors respectively given by $A, B, C, D$.  Note that $\rank(AC) \le \min(\rank A, \rank C)$ and the rank of the row and column vectors are at most $1$.  It follows that 
$$\rank(AC + BD) \le \rank{AC} + \rank{BD} \le 2,$$
but we know that $\rank P = 3$, so we cannot have $P = AC + BD$.
\end{proof}
\pagebreak
\subsection{B2 - Combinatorics} 
Let $n$ be a positive integer. Starting with the sequence $1,\frac{1}{2}, \frac{1}{3} , \cdots , \frac{1}{n}$, form a new sequence of $n -1$ entries $\frac{3}{4}, \frac{5}{12},\cdots ,\frac{2n -1}{2n(n -1)}$, by taking the averages of two consecutive entries in the first sequence. Repeat the averaging of neighbors on the second sequence to obtain a third sequence of $n -2$ entries and continue until the final sequence consists of a single number $x_n$. Show that $x_n < \frac{2}{n}$.
\begin{proof}
We claim that $x_n = \frac{2}{n} - \frac{1}{n2^{n-1}}$, which proves the result.   

First, we show by induction that the $j$-th entry of the $k$-th sequence is given by 
$$\frac{1}{2^{k-1}} \sum_{i=1}^{k} \frac{1}{i + j - 1} \binom{k-1}{i -1}.$$
For $k = 1$, the formula gives the desired starting sequence.  If we suppose it holds for the $k$-th row, then note that 
\begin{align*}
\frac{1}{2} &\left (\frac{1}{2^{k-1}} \sum_{i=1}^{k} \frac{1}{i + j - 1} \binom{k - 1}{i - 1} +  \frac{1}{2^{k-1}} \sum_{i=1}^{k} \frac{1}{i + (j + 1) - 1} \binom{k - 1}{i - 1} \right) \\
&= \frac{1}{2^k} \left (\frac{1}{j} + \frac{1}{k + j } + \sum_{i=2}^{k-1} \frac{1}{i + j } \left (\binom{k-1}{i-2} + \binom{k-1}{i-1} \right) \right) \\
&= \frac{1}{2^k} \left (\frac{1}{j} + \frac{1}{k + j } + \sum_{i=2}^{k-1} \frac{1}{i + j } \binom{k}{i-1}\right) \\
&= \frac{1}{2^k} \sum_{i=1}^{k} \frac{1}{i + j - 1 } \binom{k}{i-1}.
\end{align*}
Using this result, it follows that 
\begin{align*}
x_n &= \frac{1}{2^{n-1}} \sum_{i=1}^n \frac{1}{i} \binom{n-1}{i-1} \\
&= \frac{1}{2^{n-1}} \sum_{i=1}^n \frac{1}{n} \binom{n}{i} \\
&= \frac{1}{n2^{n-1}} (2^n - 1) \\
&= \frac{2}{n} - \frac{1}{n2^{n-1}}.
\end{align*}
\end{proof}
\pagebreak
\subsection{B3 - Number Theory}
Show that for each positive integer n,\[n!=\prod_{i=1}^n \; \text{lcm} \; \{1, 2, \ldots, \left\lfloor\frac{n}{i} \right\rfloor\}\](Here lcm denotes the least common multiple, and $\lfloor x\rfloor$ denotes the greatest integer $\le x$.)

\begin{proof}
Let $v(n)$ for $p$ prime, $n \in \N$ denote the exponent of $p$ in the prime factorization of $n$.  Note that 
\begin{align*}
v_p\left ( \prod_{k=1}^n \lcm \{1, 2, \dots, \floor{n/k}\}\right) &= \sum_{k=1}^n v_p \left (\lcm\{1, 2, \dots, \floor{n/k}\} \right) \\
&= \sum_{k=1}^n \floor{\log_p \floor{n/k}} \\
&= \sum_{k=1}^n \sum_{\ell : \floor{n/k} \ge p^\ell} 1 \\
&= \sum_{\ell=1}^\infty \floor{n/p^\ell}.
\end{align*}
This is exactly $v_p(n!)$ by Legendre's Theorem.  
\end{proof}
\subsection{B4 - Algebra}
Let $f(z) = az^4+ bz^3+ cz^2+ dz + e = a(z -r_1)(z -r_2)(z -r_3)(z -r_4)$ where $a, b, c, d, e$ are integers, $a \not= 0$. Show that if $r_1 + r_2$ is a rational number, and if $r_1 + r_2 \neq r_3 + r_4$, then $r_1r_2$ is a rational number.
\begin{proof}
Let $s_1 = r_1 + r_2$, $s_2 = r_3 + r_4$, $p_1 = r_1r_2$, $p_2 = r_3r_4$.  Without loss of generality, we may assume $f$ is a monic polynomial with rational coefficients.  Note that we can write 
\begin{align*}
f(z) &= (z^2 - s_1z + p_1)(z^2 - s_2 z + p_2) \\
&= z^4 - (s_1 + s_2) z^3 + (p_1 + p_2 + s_1s_2)z^2 - (s_1p_2 + s_2p_1)z + p_1p_2.
\end{align*}
Now, note the following:
\begin{enumerate}
\item Since $-s_1 - s_2 = b \in \Q$ and $s_1 \in \Q$, we have that $s_2 = -s_1 - b \in \Q$.  
\item Since $p_1 + p_2 + s_1s_2 = c \in \Q$ and $s_1s_2 \in \Q$, we have that $p_1 + p_2 = c - s_1s_2 \in \Q$.
\item We can write 
\begin{align*}
d &= -s_1p_2 - s_2p_1 \\
&= -s_1p_2 - s_2p_1 + s_1p_1 - s_1p_1 \\
&= -s_1(p_1 + p_2) + (s_1 - s_2)p_1.
\end{align*}
Since $s_1 \ne s_2$, it follows that 
$$p_1 = \frac{d + s_1(p_1 + p_2)}{s_1 - s_2} \in \Q.$$
\end{enumerate}
\end{proof}
\pagebreak
\subsection{B5 - Geometry}
Let $A$, $B$ and $C$ be equidistant points on the circumference of a circle of unit radius centered at $O$, and let $P$ be any point in the circle's interior. Let $a$, $b$, $c$ be the distances from $P$ to $A$, $B$, $C$ respectively. Show that there is a triangle with side lengths $a$, $b$, $c$, and that the area of this triangle depends only on the distance from $P$ to $O$.

\begin{proof}
Let $\omega = e^{2\pi i / 3}$, $A = 1$, $B = \omega$, $C = \omega^2$, $P = z \in \C$ with $|z| < 1$.  We have 
$$a = |z - 1|, b = |z - \omega|,  c = |z - \omega^2|.$$

Note that 
\begin{align*}
(z - 1) + \omega(z - \omega) + \omega^2(z - \omega^2) &= z(1 + \omega + \omega^2) - (1 + \omega^2 + \omega^4) = 0.
\end{align*}
The corresponding triangle, where we visualize the complex numbers as vectors that are sides of the triangle, has side lengths of $a, b, c$ as desired.  

The area of the triangle is given by 
\begin{align*}
|(z-1) \bar{\omega(z - \omega)} - \bar{z - 1} \omega(z - \omega)|/4 &= |(z - 1) (\omega^2\bar{z} - \omega) - (\bar{z} - 1) (\omega z - \omega^2)|/4 \\
&= |z \bar{z} \omega^2 - \omega^2 \bar{z} - z\omega + \omega - z\bar{z} \omega + \omega z + \bar{z} \omega^2  - \omega^2|/4 \\
&= |(z \bar{z} - 1) (\omega^2 - \omega)|/4\\
&= \frac{(1 - |z|^2)\sqrt{3}}{4},
\end{align*}
which is a function of $z$, as desired. 
\end{proof}
\pagebreak
\subsection{B6 - Analysis}
Let $f(x)$ be a continuous real-valued function defined on $[0, 1]$.  Show that 
$$\int_{0}^1 \int_{0}^1 |f(x) + f(y)| \,dxdy \ge \int_0^1 |f(x)|\,dx.$$

\begin{proof}
Let $f^+ = \max(f(x), 0)$ and $f^- = f^+ - f$.  Let $A = \supp f^+$, $B = \supp f^-$.  We will denote $\|g\| = \int_{0}^1 |g(x)|\,dx$.

Note that 
$$\int_0^1 \int_0^1 |f(x) + f(y)|\,dxdy = \left (\iint_{A \times A} + \iint_{B \times B} + 2\iint_{A \times B} \right) |f(x) + f(y) | \,dxdy.$$

Note that 
\begin{align*}
\iint_{A \times A} |f(x) + f(y)| \,dxdy &= \iint_{A \times A} (f(x) + f(y)) \,dx dy \\
&= \iint_{A \times A} f(x) \,dxdy + \iint_{A \times A} f(y) \,dx dy \\
&=2|A| \|f^+\|.
\end{align*}
Similarly,
$\iint_{B \times B} |f(x) + f(y)| \,dxdy = 2|B| \|f^-\|$.

Finally, note that 
\begin{align*}
\iint_{A \times B} |f(x) + f(y)| \,dxdy & = \iint_{A \times B} |f^+(x) - f^-(y)| \,dxdy \\
&\ge \left | \iint_{A \times B} (f^+(x) - f^-(y))\,dxdy \right| \\
&= ||B| \|f^+\| - |A| \|f^-\||.
\end{align*}

Combining the results, we have that 
$$\int_{0}^1 \int_{0}^1 |f(x) + f(y)| \,dxdy \ge 2|A| \|f^+\| + 2|B| \|f^-\| + 2 ||B| \|f^+\| - |A| \|f^-\||.$$

Squaring both sides of the expression, we have that 
\begin{align*}
&\left (\int_{0}^1 \int_{0}^1 |f(x) + f(y)| \,dxdy \right)^2 \ge \left (2|A| \|f^+\| + 2|B| \|f^-\| + 2 ||B| \|f^+\| - |A| \|f^-\|| \right)^2 \\
&= 4 (|A| \|f^+\| + |B| \|f^- \| + ||B| \|f^+\| - |A| \|f^-\||)^2 \\
&= 4 (|A| \|f^+\| + |B| \|f^- \| )^2 + 4 (|B| \|f^+\| - |A| \|f^-\|)^2 + 8 (|A| \|f^+\| + |B| \|f^- \| )||B| \|f^+\| - |A| \|f^-\|| \\
&\ge 4(|A|^2 \|f^+\|^2 + |B|^2 \|f^-\|^2 + |A|^2 \|f^-\|^2 + |B|^2 \|f^+\|^2) \\
&\ge 4(|A|^2 + |B|^2) (\|f^+\|^2 + \|f^-\|^2) \\
&\ge (|A| + |B|)^2 (\|f^+\| + \|f^-\|)^2 \\
&= (1)^2 (\|f\|)^2 \\
&= \left (\int_0^1 |f(x)|\,dx \right)^2.
\end{align*}
\end{proof}
\pagebreak
\section{Putnam - 2004} 
\subsection{A1 - Number Theory}
Basketball star Shanille O'Keal's team statistician keeps track of the number, $S(N),$ of successful free throws she has made in her first $N$ attempts of the season. Early in the season, $S(N)$ was less than $80\%$ of $N,$ but by the end of the season, $S(N)$ was more than $80\%$ of $N.$ Was there necessarily a moment in between when $S(N)$ was exactly $80\%$ of $N$?
\begin{proof}
We claim that such a moment must exist.  Suppose not.  Then, there exists some value of $N$ so that 
$$\frac{S(N)}{N} < \frac{4}{5}, \frac{S(N) + 1}{N + 1} > \frac{4}{5}.$$

Cross-multiplying, this gives that $$5S(N) < 4N, 5S(N) > 4N -1,$$
but this system of inequalities has no solutions in integers.  
\end{proof}
\subsection{A2 - Geometry}
For $i=1,2,$ let $T_i$ be a triangle with side length $a_i,b_i,c_i,$ and area $A_i.$ Suppose that $a_1\le a_2, b_1\le b_2, c_1\le c_2,$ and that $T_2$ is an acute triangle. Does it follow that $A_1\le A_2$?
\begin{proof}
We claim that it does follow.

Let $R_i$ be the angle between $a_i$ and $b_i$, $S_i$ the angle between $b_i$ and $c_i$ and $T_i$ the angle between $c_i$ and $a_i$.  Note that 
$$R_1 + S_1 + T_1 = R_2 + S_2 + T_2 = \pi,$$
so we must have at least one of $R_1 \le R_2$, $S_1 \le S_2$ or $T_1 \le T_2$.  Without loss of generality, suppose that $R_1 \le R_2$.  We have that 
$$A_1 = \frac{a_1b_1 \sin R_1}{2} \le \frac{a_2 b_2 \sin R_2}{2} = A_2,$$
as desired.
\end{proof}
\subsection{A3 - Algebra}
Define a sequence $\{u_n\}_{n=0}^{\infty}$ by $u_0=u_1=u_2=1,$ and thereafter by the condition that
$\det\begin{vmatrix} u_n & u_{n+1} \\ u_{n+2} & u_{n+3} \end{vmatrix}=n!$
for all $n\ge 0.$ Show that $u_n$ is an integer for all $n.$ (By convention, $0!=1$.)
\begin{proof}
Show by induction that $a_{2n} = (2n-1)(2n-3) \dots (3)(1)$, $a_{2n+1} = (2n)(2n-2)\dots(2)$.
\end{proof}
\subsection{A4 - Algebra}
Show that for any positive integer $n$ there is an integer $N$ such that the product $x_1x_2\cdots x_n$ can be expressed identically in the form
\[x_1x_2\cdots x_n=\sum_{i=1}^Nc_i(a_{i1}x_1+a_{i2}x_2+\cdots +a_{in}x_n)^n\]
where the $c_i$ are rational numbers and each $a_{ij}$ is one of the numbers, $-1,0,1.$
\begin{proof}
Define $P(x_1, \dots, x_n) = \sum_{e_i \in \{-1, 1\}} (e_1 e_2 \dots e_n) (e_1x_1 + \dots + e_nx_n)^n$.  Note that 
\begin{align*}
P(0, x_2, \dots, x_n) &= \sum_{e_i \in \{-1, 1\}} (e_1 e_2 \dots e_n) (e_2x_2 \dots + e_nx_n)^n \\
&= \sum_{e_1 = 1, e_i \in \{-1, 1\}} (e_2 \dots e_n) (e_2x_2 \dots + e_nx_n)^n +  \sum_{e_1 = -1, e_i \in \{-1, 1\}} (-e_2 \dots e_n) (e_2x_2 \dots + e_nx_n)^n \\
&= 0.
\end{align*}
Similarly, $P(x_1, \dots, x_i, 0, x_{i+2}, \dots, x_n) = 0$ so it follows that $x_i \mid P(x_1, \dots, x_n)$ for all $i$.  This implies that $x_1x_2\dots x_n \mid P(x_1, \dots, x_n)$.  So we must have 
$$P(x_1, \dots, x_n) = x_1\dots x_n Q(x_1, \dots, x_n).$$
However, $\deg P = n$, which implies that $\deg Q = 0$.  In other words,
$$P(x_1, \dots, x_n) = \lambda x_1 \dots x_n$$
for some $\lambda \ne 0$.  It is clear that $\lambda \in \Z$ since $P(x_1, \dots, x_n)$ is an integer linear combination of integer polynomials.  Then, $x_1 \dots x_n = \frac{1}{\lambda}P(x_1, \dots, x_n)$ is in the desired form.  
\end{proof}
\subsection{A5 - Combinatorics}
	An $m\times n$ checkerboard is colored randomly: each square is independently assigned red or black with probability $\frac12.$ we say that two squares, $p$ and $q$, are in the same connected monochromatic region if there is a sequence of squares, all of the same color, starting at $p$ and ending at $q,$ in which successive squares in the sequence share a common side. Show that the expected number of connected monochromatic regions is greater than $\frac{mn}8.$
\begin{proof}
Construct a graph $G(V, E)$ with $|V| = mn$ with vertices corresponding to the squares of the checkerboard so that adjacent vertices are connected by an edge if the corresponding squares on the checkerboard are the same color.  Note that the number of connected components of $G$, $C$ is at least $|V| - |E|$.

Let $A$ be the number of $4$-cycles of $G$(2-by-2 monochromatic squares).  Note that if we delete the bottom edge from each $4$-cycle, it does not affect the number of connected components of $G$ and we delete an edge exactly once for each $4$-cycle.  It follows that $C \ge |V| - |E| + A$.

Now, note that 
$$\mathbb{E}(|E|) = \frac{m(n-1) + n(m-1)}{2}, \mathbb{E}(A) = \frac{(m-1)(n-1)}{8}.$$
It follows by linearity of expectation that 
\begin{align*}
\mathbb{E}(C) &\ge \mathbb{E}(|V|) - \mathbb{E}(|E|) + \mathbb{E}(A) \\
&= mn - \frac{m(n-1) + n(m-1)}{2} +  \frac{(m-1)(n-1)}{8} \\
&= \frac{mn + 3m + 3n + 1}{8} > \frac{mn}{8}.
\end{align*}
\end{proof}
\subsection{A6 - Analysis}
Suppose that $f(x,y)$ is a continuous real-valued function on the unit square $0\le x\le1,0\le y\le1.$ Show that

$$\int_0^1\left(\int_0^1f(x,y)dx\right)^2dy + \int_0^1\left(\int_0^1f(x,y)dy\right)^2dx\le\left(\int_0^1\int_0^1f(x,y)dxdy\right)^2 + \int_0^1\int_0^1\left[f(x,y)\right]^2dxdy.$$
\begin{proof}
Let 
$$I_1 = \int_0^1\int_0^1\left[f(x,y)\right]^2dxdy = \int_{[0, 1]^4} f(x, y) f(x, y) \,dx dy du dv$$
$$I_2 = \left ( \int_0^1\int_0^1f(x,y)\,dxdy \right)^2 = \int_{[0, 1]^4} f(x, y) f(u, v) \,dx dy du dv$$
$$I_3 =   \int_0^1 \left (\int_0^1f(x,y)\,dx\right)^2dy = \int_{[0, 1]^4} f(x, y) f(u, y) \,dx dy du dv$$
$$I_4 =   \int_0^1 \left (\int_0^1f(x,y)\,dy\right)^2dx = \int_{[0, 1]^4} f(x, y) f(x, v) \,dx dy du dv.$$

We wish to show that $I_1 + I_2 - I_3 - I_4 \ge 0$, which is equivalent to showing 
$$I = \int_{[0, 1]^4} f(x, y) \left [f(x, y) + f(u, v) - f(u, y) - f(x, v) \right]dxdydudv.$$
By swapping the $x \leftrightarrow u$, $y \leftrightarrow v$, we also have 
$$I = \int_{[0, 1]^4} f(u, y) \left [f(u, y) + f(x, v) - f(x, y) - f(u, v) \right]dxdydudv.$$
$$I = \int_{[0, 1]^4} f(x, v) \left [f(x, v) + f(u, y) - f(u, v) - f(x, y) \right]dxdydudv.$$
$$I = \int_{[0, 1]^4} f(u, v) \left [f(u, v) + f(x, y) - f(x, v) - f(u, y) \right]dxdydudv.$$
Then, note that 
$$4I =  \int_{[0, 1]^4} \left (f(x, y) - f(x, v) - f(u, y) + f(u, v) \right)^2 \,dxdydudv \ge 0,$$
which proves the result.  
\end{proof}
\subsection{B1 - Algebra}
Let $P(x)=c_nx^n+c_{n-1}x^{n-1}+\cdots+c_0$ be a polynomial with integer coefficients. Suppose that $r$ is a rational number such that $P(r)=0$. Show that the $n$ numbers
$c_nr, c_nr^2+c_{n-1}r, c_nr^3+c_{n-1}r^2+c_{n-1}r, \dots, c_nr^n+c_{n-1}r^{n-1}+\cdots+c_1r$
are all integers.
\begin{proof}
We can write Note that $P(r)/r^{k} = 0$, so we can write
$$c_n r^{n-k} \dots c_{n-k+1}r = - (c_{n-k}  + c_{n-k-1}r^{-1} + \dots + r^{-k}).$$
Rewriting $r = \frac{p}{q}$ with $\gcd(p, q) = 1$, we have
$$\frac{c_n p^{n-k} \dots c_{n-k+1}pq^{n-k-1}}{q^{n-k}} = - \frac{c_{n-k}p^k  + c_{n-k-1}q p^{k-1} + \dots + q^k}{p^k}.$$
Since $\gcd(p, q) = 1$ and both numerators are integers, it follows that both sides of the equation must be integer as desired.
\end{proof}
\subsection{B2 - Algebra}
Let $m$ and $n$ be positive integers. Show that
$\frac{(m+n)!}{(m+n)^{m+n}} < \frac{m!}{m^m}\cdot\frac{n!}{n^n}$
\begin{proof}
Note that
\begin{align*}
\frac{(m+n)!}{m!n!} = \binom{m+n}{m} &< \frac{(m+n)^{m+n}}{m^mn^n}  \\
&= \frac{1}{m^mn^n} \sum_{k=0}^{m+n} \binom{m+n}{k} m^k n^{m+n-k} \\
&=  \sum_{k=0}^{m+n} \binom{m+n}{k} \left( \frac{n}{m}\right)^{m-k},\\
\end{align*}
which is obvious.
\end{proof}
\subsection{B3 - Algebra/Geometry}
Determine all real numbers $a>0$ for which there exists a nonnegative continuous function $f(x)$ defined on $[0,a]$ with the property that the region
$R=\{(x,y): 0\le x\le a, 0\le y\le f(x)\}$
has perimeter $k$ units and area $k$ square units for some real number $k$.
\begin{proof}
For $a > 2$, we can take $f(x) = \frac{2a}{a-2}$ so that the area and perimeter are given by $\frac{2a^2}{a-2}$.

For $a \le 2$, we claim no such functions exist. Let $f \in C[0, a]$ and let $x_0 = \operatorname{argmax}_{[0, a]} f(x)$. Note that the area of the region is bounded by $af(x_0)$. For the perimeter, note that $(0, 0), (a, 0)$ and $(x_0, f(x_0))$ split up the boundary of $R$ into $3$ regions. The distance from $(0, 0)$ to $(a, 0)$ is at least $a$, the distance from $(0, 0)$ to $(x_0, f(x_0))$ is at least $f(x_0)$ and the distance from $(a, 0)$ to $(x_0, f(x_0))$ is at least $f(x_0)$. It follows that the perimeter is at least
$$2f(x_0) + a > af(x_0),$$using the fact that $a \le 2$. It follows that we cannot have equal perimeter and area units.
\end{proof}
\subsection{B4 - Algebra/Geometry}
Let $n$ be a positive integer, $n \ge 2$, and put $\theta=\frac{2\pi}{n}$. Define points $P_k=(k,0)$ in the xy-plane, for $k=1,2,\dots,n$. Let $R_k$ be the map that rotates the plane counterclockwise by the angle $\theta$ about the point $P_k$. Let $R$ denote the map obtained by applying in order, $R_1$, then $R_2$, ..., then $R_n$. For an arbitrary point $(x,y)$, find and simplify the coordinates of $R(x,y)$.
\begin{proof}
We claim that $R(x, y) = (x + n, y)$.  Translate into complex numbers so that $(x, y)$ corresponds to $x + iy$.    Let $\theta = 2\pi i /n$.  It is easy to show by induction that 
$$R(z) = (z-1) e^{ni \theta} - e^{(n-1)i\theta} - \dots - e^{i\theta} + n.$$
Note that 
\begin{align*}
R(z) &= (z-1) e^{ni \theta} - e^{(n-1)i\theta} - \dots - e^{i\theta} + n \\
&= (z-1) + e^{ni\theta} - e^{ni\theta}- e^{(n-1)i\theta} - \dots - e^{i\theta} + n \\
&= (z - 1) + 1 - 0 + n \\
&= z + n.
\end{align*}
It follows that $R(x, y) = (x + n, y)$, which proves the result. 
\end{proof}
\pagebreak
\subsection{B5 - Analysis}
Evaluate $\lim_{x\to 1^-}\prod_{n=0}^{\infty}\left(\frac{1+x^{n+1}}{1+x^n}\right)^{x^n}$.
\begin{proof}
Let $L = \prod_{n=0}^{\infty}\left(\frac{1+x^{n+1}}{1+x^n}\right)^{x^n}$.  Note that 
\begin{align*}
\log L &= \sum_{n=0}^{\infty} x^n \log (1 + x^{n + 1}) - x^n \log (1 + x^n) \\
&= \frac{1}{x}\sum_{n=0}^{\infty} x^{n+1} \log (1 + x^{n+1})  - \sum_{n=0}^{\infty} x^n \log(1 + x^n) \\
&=\left (\frac{1}{x} - 1 \right) \sum_{n=1}^\infty x^n \log(1 + x^n) - \log 2.
\end{align*}
Then, note that 
\begin{align*}
\sum_{n=1}^\infty x^n \log (1 + x^n) &= \sum_{n=1}^\infty \sum_{j=1}^\infty \frac{(-1)^j x^{n(j + 1)}}{j}.
\end{align*}
Then, note that the sum converges absolutely since 
$$\sum_{n=1}^\infty \sum_{j=1}^\infty \frac{x^{n(j + 1)}}{j} = -\sum_{n=1}^\infty x^n \log(1 - x^n) \le -\sum_{n=1}^\infty x^n \log (1 - x) = \frac{x\log(1 - x)}{x - 1}.$$

Hence, we can apply Fubini's Theorem to obtain
\begin{align*}
\sum_{n=1}^\infty \sum_{j=1}^\infty \frac{(-1)^j x^{n(j + 1)}}{j} &= \sum_{j=1}^\infty \frac{(-1)^j}{j}\sum_{n=1}^\infty x^{n(j + 1)} = \sum_{j=1}^\infty \frac{(-1)^j}{j} \frac{x^{j + 1}}{1 - x^{j + 1}}.
\end{align*}
Then,
\begin{align*}
\left (\frac{1}{x} - 1 \right) \sum_{j=1}^\infty \frac{(-1)^j}{j} \frac{x^{j + 1}}{1 - x^{j + 1}} &= \sum_{j=1}^\infty \frac{(-1)^j}{j} \frac{x^{j} (1 - x)}{1 - x^{j + 1}}.
\end{align*}

Note that the sum converges uniformly since $ \frac{x^{j} (1 - x)}{1 - x^{j + 1}} \le \frac{1}{j}$ and $\sum_{j=1}^\infty \frac{1}{j^2} < \infty$.  Therefore, we can take limits term by term to obtain
$$ \frac{x^{j} (1 - x)}{1 - x^{j + 1}} = \frac{x^j(1 - x)}{(1 - x)(1 + x + \dots + x^{j})}\to \frac{1}{j + 1}.$$

Finally, note that 
\begin{align*}
\sum_{j=1}^\infty \frac{(-1)^j}{j(j + 1)} &= \sum_{j=1}^\infty (-1)^j\left (\frac{1}{j} - \frac{1}{j + 1} \right) \\
&= \sum_{j=1}^\infty \frac{(-1)^j}{j} + \sum_{j=2}^\infty \frac{(-1)^j}{j} \\
&= 2\sum_{j=1}^\infty \frac{(-1)^j}{j} - 1 \\
&= 2 \log 2 - 1.
\end{align*}
It follows that $\log L \to \log 2 - 1$, so we obtain $L = e^{\log 2 - 1} = 2/e$.
\end{proof}
\pagebreak
\subsection{B6 - Analysis} 
Let $A$ be a nonempty set of positive integers, and let $N(x)$ denote the number of elements of $A$ not exceeding $x$. Let $B$ denote the set of positive integers $b$ that can be written in the form $b=a-a^{\prime}$ with $a\in A$ and $a^{\prime}\in A$. Let $b_1<b_2<\cdots$ be the members of $B$, listed in increasing order. Show that if the sequence $b_{i+1}-b_i$ is unbounded, then $\lim_{x\to \infty}\frac{N(x)}{x}=0$.
\begin{proof}
Suppose $\lim_{x \to \infty} \frac{N(x)}{x} > 0$.  Call $T = \{t_1, \dots, t_n\}$ good if all the $A+t_i = \{a + t_i: a \in A\}$ are mutually pairwise disjoint.  We start by proving a lemma.
\begin{lemma}
If $T = \{t_1, \dots, t_n\}$ is good and $\lim_{x \to \infty} \frac{N(x)}{x} > 0$, then 
$$|T| \le \frac{1}{\limsup_{x \to \infty} \frac{N(x)}{x}}$$
\end{lemma}
\begin{proof}
Note that 
\begin{align*}
x &\ge \left | \bigcup_{k=1}^n (A + t_i) \cap [0, x]\right| \\
&= \sum_{k=1}^n |(A + t_i) \cap [0, x]| \\
&= \sum_{k=1}^n N(x - t_i) \\
&\ge \sum_{k=1}^n (N(x) - t_i) \\
& = |T| N(x) - \sum_{k=1}^{n} t_i.
\end{align*}
After rearranging, we obtain
$$\frac{N(x)}{x} \le \frac{1 + \sum_{k=1}^n \frac{t_i}{x}}{|T|},$$
which implies the desired result upon taking the limsup of both sides.  
\end{proof}
Since the size of good sets are bounded, let $T_* = \{t_1, \dots, t_n\}$ be a good set of maximal size.  For any $t \in \N \setminus T_*$, we must have that $T_* \cup \{t\}$ is not good, so there is some $t_i$ and $a_i, a_j$ such that 
$$a_i + t_i = a_j + t \rightarrow t - t_i = a_i - a_j \in B.$$

In other words, for all $t \in \N \setminus T_*$, there exists $i \in [1, n] \cap \Z$ such that $t - t_j \in B$.  Applying the result for $t = b_{i+1}$, there is some $j \in [1, n] \cap \Z$ such that $b_{i+1} - t_j = b \in B$, so $t_j = b_{i + 1} - b \ge b_{i + 1} - b_i$.  Since $t_j \le \max T$, we have that $b_{i + 1} - b_i \le \max T$ is bounded, which proves the result.
\end{proof}
\pagebreak
\section{Putnam 2005}
\subsection{A1 - Number Theory}
Show that every positive integer is a sum of one or more numbers of the form $2^r3^s,$ where $r$ and $s$ are nonnegative integers and no summand divides another.
(For example, $23=9+8+6.)$
\begin{proof}
We proceed by strong induction.  Note that we can take $1 = 2^0$ which handles the base case.  We prove the even and odd cases separately.  Suppose the result is true for $n=1, 2, \dots, 2k-1$.  For $n = 2k$, note that we can write it as 
$$n = 2k = 2\sum_{i=1}^\ell 2^{r_i}3^{s_i} = \sum_{i=1}^{\ell} 2^{r_i + 1} 3^{s_i}.$$
If we have that $2^{r_i}3^{s_i} \nmid 2^{r_j} 3^{s_j}$ for any $i \ne j$ then it follows that $2^{r_i + 1}3^{s_i} \nmid 2^{r_j + 1} 3^{s_j}$, since otherwise we have $2^{r_j + 1} 3^{s_j} = m 2^{r_i + 1}3^{s_i}$ which implies that $2^{r_j} 3^{s_j} = m 2^{r_i}3^{s_i}$, a contradiction.

Now, suppose the result is true for $n = 1, \dots, 2k$.  For $n = 2k+1$, let $m = \floor{\log_3(n)}$.  Note that we have $3^m \le n < 3^{m + 1}$.  If $n = 3^m$, then we are done.  Otherwise, note that $n - 3^m$ is even and less than $n$, so we can write 
$$n = 3^m + (n - 3^m) = 3^m + \sum_{i=1}^\ell 2^{r_i + 1}3^{s_i}$$
and note that 
$$2^{r_i + 1} 3^{s_i} \le n - 3^m < 3^{m + 1} - 3^m = 2 \cdot 3^m,$$
so it follows that $3^m > 2^{r_i}3^{s_i} \ge 3^{s_i}$, so we must have $s_i < m$ which implies that $3^m \nmid 2^{r_i + 1}3^{s_i}$.  It's also clear that $2^{r_i + 1} 3^{s_i }\nmid 3^m$ for any $i$, which completes the proof.
\end{proof}
\pagebreak
\subsection{A2 - Combinatorics}
Let $S=\{(a,b)|a=1,2,\dots,n,b=1,2,3\}$. A rook tour of $S$ is a polygonal path made up of line segments connecting points $p_1,p_2,\dots,p_{3n}$ is sequence such that

(i) $p_i\in S,$

(ii) $p_i$ and $p_{i+1}$ are a unit distance apart, for $1\le i<3n,$

(iii) for each $p\in S$ there is a unique $i$ such that $p_i=p.$

How many rook tours are there that begin at $(1,1)$ and end at $(n,1)?$

\begin{proof}
We claim the number of rook tours is given by $2^{n-2}$ for $n \ge 2$ and $0$ for $n = 1$.
Let $A_n$ be the set of rook tours from $(1, 1)$ to $(n, 1)$ and let $B_n$ be the set of rook tours from $(1, 3)$ to $(n, 1)$.  It is clear that $|A_1| = 0$.
\begin{lemma} For $n > 1$,
$$|A_n| = |B_1| + \dots + |B_{n-1}|.$$
\end{lemma}
\begin{proof}
We prove the result by strong induction.  For $n = 2$, it is clear that $|A_2| = 1 = |B_1|$.  

Suppose the result is true for $2 \le n \le k$.  Note that in order to have a rook tour from $(1, 1) \to (k+1, 1)$ we must first go from $(1, 1) \to (\ell, 1)$ for some $1 \le \ell \le k$, then go from $(\ell, 1) \to (\ell, 2)$, and then take a path $(\ell, 2) \to (1, 2) \to (1, 3) \to (\ell, 3)$ in order to cover all the points in the rook tour.  Finally, the number of paths from $(\ell. 3) \to (k +1, 1)$ is given by $|B_{k - \ell + 1}|$.  It follows that 
$$|A_{k + 1}| = |B_1| + \dots  + |B_k|,$$
which proves the result.  
\end{proof}

We can similarly prove by strong induction that $|B_n| = |A_1| + \dots + |A_{n-1}|$ for $n > 1$ and $|B_1| = 1$.  This implies that 
$$|A_n| = |A_{n-1}| + |B_{n-1}|, \quad |B_n| = |A_{n-1}| + |B_{n-1}|$$
for $n > 2$, which implies that $|A_n| = 2|A_{n-1}|$ for $n > 2$.  It follows that $|A_n| = 2^{n-2}|A_2| = 2^{n-2}$ for $n > 2$, $|A_2| = 1$ and $|A_1| = 0$.
\end{proof}
\pagebreak
\subsection{A3 - Algebra}
Let $p(z)$ be a polynomial of degree $n,$ all of whose zeros have absolute value $1$ in the complex plane. Put $g(z)=\frac{p(z)}{z^{n/2}}.$ Show that all zeros of $g'(z)=0$ have absolute value $1.$
\begin{proof}
Note that we can write $p(z) = a \prod_{j=1}^n (z - \omega_j)$ where $|\omega_j| = 1$ for all $j$. It follows that 
$$\log g(z) = \log a + \sum_{j=1}^n \log (z - \omega_j) - \frac{n}{2} \log z = \log a + \sum_{j=1}^n \left (\log (z - \omega_j) - \frac{\log z}{2} \right).$$

Taking the derivative of both sides, we obtain
\begin{align*}
\frac{g'(z)}{g(z)} &= \sum_{j=1}^n \left (\frac{1}{z - \omega_j} - \frac{1}{2z} \right) \\
&= \frac{1}{2z} \sum_{j=1}^n \frac{z + \omega_j}{z - \omega_j} \\
&= \frac{1}{2z} \sum_{j=1}^n \frac{|z|^2 - 1 + \omega_j \bar{z} - z \bar{\omega_j}}{|z - \omega_j|^2} \\
&= \frac{1}{2z} \sum_{j=1}^n \left ( \frac{|z|^2 - 1}{|z - \omega_j|^2} + i\frac{\operatorname{Im}(\omega_j \bar{z})}{|z - \omega_j|^2} \right).
\end{align*}

It follows that 
$$\operatorname{Re}\left (\frac{zg'(z)}{g(z)} \right) = \frac{|z|^2 - 1}{2} \sum_{j=1}^n \frac{1}{|z - \omega_j|^2}.$$
Since $\sum_{j=1}^n \frac{1}{|z - \omega_j|^2} > 0$, it follows that the real part of $\frac{zg'(z)}{g(z)}$ is zero if and only if $|z|^2 - 1 = 0$, which implies that $|z|^2 = 1$.  It follows that all the zeros of $g'(z)$ must either satisfy $|z|^2 = 1$ or $g(z) = 0$ which gives the desired result since the zeros of $g(z)$ lie on the unit circle on the complex plane.  
\end{proof}
\pagebreak
\subsection{B1 - Algebra}
Find a nonzero polynomial $P(x,y)$ such that $P(\lfloor a\rfloor,\lfloor 2a\rfloor)=0$ for all real numbers $a.$
\begin{proof}
Take $P(x, y) = (2x - y)(2x - y + 1)$.  Let $\{a\} = a - \floor{a}$.  Note that $\floor{2a} = 2\floor{a}$ when $\{a\} < \frac{1}{2}$ and $\floor{2a} = 2 \floor{a} + 1$ when $\{a\} \ge \frac{1}{2}$.
\end{proof}
\subsection{B2 - Algebra}
Find all positive integers $n,k_1,\dots,k_n$ such that $k_1+\cdots+k_n=5n-4$ and
\[ \frac1{k_1}+\cdots+\frac1{k_n}=1. \]
\subsection{B3 - Calculus}
Find all differentiable functions $f: (0,\infty)\mapsto (0,\infty)$ for which there is a positive real number $a$ such that
\[ f'\left(\frac ax\right)=\frac x{f(x)} \]
for all $x>0.$


\pagebreak
\section{Putnam 2020}
\subsection{A1 - Number Theory}
How many positive integers $N$ satisfy all of the following three conditions?
(i) $N$ is divisible by $2020$.
(ii) $N$ has at most $2020$ decimal digits.
(iii) The decimal digits of $N$ are a string of consecutive ones followed by a string of consecutive zeros.
\begin{proof}
We claim there are $508536$ positive integers satisfying the claim.  Note that the integer with decimal representation given by $m$ $1$'s followed by $k$ zeros is given by 
$$\frac{10^m - 1}{9} \cdot 10^k.$$
Since $2020 = 2^2 \cdot 5 \cdot 101$, we must have $2^2 \cdot 5 \mid 10^k$ and $101 \mid \frac{10^m - 1}{9}.$  The first condition gives $k \ge 2$ and the second condition gives 
$$10^m \equiv 1 \pmod{101} \Rightarrow 4 \mid m.$$
Finally, we need to satisfy the condition that $m + k \le 2020$.  We can write $m = 4 \ell$ and $k = 2 + j$ in order to rewrite this as 
$$4\ell + j \le 2018, \ell \ge 1, j \ge 0 \Rightarrow 0 \le j \le 2018 - 4\ell.$$
Since $2018 = 4(504) + 2$, the number of solutions is given by 
\begin{align*}
\sum_{\ell = 1}^{504} (2018 - 4\ell + 1) &= \sum_{\ell = 1}^{504} (2019 - 4\ell) \\
&= (504)(2019) - 4 \sum_{\ell=1}^{504} \ell \\
&= (504)(2019) - (504)(1010) \\
&= (504)(1009) \\
&= 508536.
\end{align*}


\end{proof}


\pagebreak
\subsection{A2 - Combinatorics}
Let $k$ be a nonnegative integer. Evaluate
\[ \sum_{j=0}^k 2^{k-j} \binom{k+j}{j}. \]
\begin{proof}
We claim the sum evaluates to $4^k$.  Note that $\binom{n + k}{j} = \binom{n + k}{k}$ so the desired expression is given by $[x^k]\{F(x)\}$ where 
\begin{align*}
F(x) &= \sum_{j=0}^k 2^{k-j} (1 + x)^{k + j} \\
&= (2)^k(1 + x)^k \sum_{j=1}^k \left (\frac{1 + x}{2} \right)^j \\
&= 2^k(1 + x)^k \left (\frac{1 - (1+x)^{k + 1}/2^{k + 1}}{1 - x} \right) \\
&= \frac{2^{k + 1}(1 + x)^k - (1 + x)^{2k + 1}}{1-x} \\
&= (2^{k + 1}(1 + x)^k - (1 + x)^{2k + 1}) \sum_{n \ge 0} x^n.
\end{align*}
It follows that 
\begin{align*}
[x^k]\{F(x)\} &=  \sum_{n=0}^k \left ( 2^{k + 1} \binom{k}{k-n} - \binom{2k + 1}{k-n}\right)\\
&= 2^{k + 1}\sum_{n=0}^k \binom{k}{n} - \sum_{n=0}^k \binom{2k + 1}{ k +1 + n} \\
&= 2^{2k+1} - 2^{2k+1}/2 \\
&= 2^{2k} \\
&= 4^k.
\end{align*}
\end{proof}

\pagebreak
\subsection{A3 - Analysis}
	Let $a_0=\pi /2$, and let $a_n=\sin (a_{n-1})$ for $n\ge 1$. Determine whether
\[ \sum_{n=1}^{\infty}a_n^2 \]converges.
\begin{proof}
We claim the series diverges.   It suffices to show that $a_n \ge \frac{1}{\sqrt{n}}$. We proceed by induction.  It is clear that $a_1 = 1 \ge \frac{1}{\sqrt{1}} = 1$.  Suppose that $a_k \ge \frac{1}{\sqrt{k}}$.  Since $\sin x \ge x - x^3 / 6$ and $\sin x$ is monotonically increasing in $[0, \pi/2]$, we have 
$$a_{k + 1} \ge \sin \left (\frac{1}{\sqrt{k}} \right) > \frac{1}{\sqrt{k}} - \frac{1}{6k\sqrt{k}} = \frac{6k-1}{6k\sqrt{k}}.$$
It suffices to show that 
$$\frac{6k-1}{6k} \ge \frac{\sqrt{k}}{\sqrt{k + 1}} \Leftrightarrow 24k^2 - 11k + 1 \ge 0,$$
which is true for $k \ge 1$.
\end{proof}
\pagebreak
\subsection{A4 - Combinatorics}
Consider a horizontal strip of $N+2$ squares in which the first and the last square are black and the remaining $N$ squares are all white. Choose a white square uniformly at random, choose one of its two neighbors with equal probability, and color tis neighboring square black if it is not already black. Repeat this process until all the remaining white squares have only black neighbors. Let $w(N)$ be the expected number of white squares remaining. Find
\[ \lim_{N\to\infty}\frac{w(N)}{N}.\]
\begin{proof}
We claim the limit is $1/e$.  Using a recursive argument, it is easy to show prove by induction that 
$$w(N) =  \sum_{k=1}^{N-2}\left ( \frac{2w(k)}{N - 1} \right) + \frac{w(N - 1)}{N - 1}.$$

This leads to the identity
$$w(N + 1) = w(N) + \frac{w(N - 1)}{N - 2}.$$
We can solve this via generating functions - define $W(z) = \sum_{k \ge 1} \frac{w(k + 1)}{k} z^k$.  From the recursive formula, we obtain

$$W(z) + 1 = \frac{1-z}{z} W'(z) \Rightarrow W(z) = \frac{e^{-z}}{1 - z} - 1.$$

Finally, note that 
$$\frac{w(n-1)}{n} = [z^n]\{W(z)\} = [z^n] \{e^{-z} \sum_{k \ge 0} z^k\} = \sum_{k=0}^n \frac{(-1)^k}{k!} \xrightarrow{n \to \infty} \frac{1}{e}.$$
\end{proof}
\pagebreak
\subsection{A5 - Combinatorics}
Let $a_n$ be the number of sets $S$ of positive integers for which
\[ \sum_{k\in S}F_k=n,\]where the Fibonacci sequence $(F_k)_{k\ge 1}$ satisfies $F_{k+2}=F_{k+1}+F_k$ and begins $F_1=1$, $F_2=1$, $F_3=2$, $F_4=3$. Find the largest number $n$ such that $a_n=2020$.
\pagebreak
\subsection{A6 - Analysis}
For a positive integer $N$, let $f_N$ be the function defined by
\[ f_N (x)=\sum_{n=0}^N \frac{N+1/2-n}{(N+1)(2n+1)} \sin\left((2n+1)x \right). \]Determine the smallest constant $M$ such that $f_N (x)\le M$ for all $N$ and all real $x$.

\begin{proof}
After partial fractions decomposition, we can write 
$$f_N(x) = \sum_{n=0}^N \left (\frac{1}{2n+1} - \frac{1}{2N + 2} \right) \sin((2n + 1)x) = \sum_{n=0}^N \frac{\sin((2n + 1)x)}{2n + 1} - \frac{1 - \cos((2N + 2)x)}{(4N + 4)\sin x}.$$

Upon taking the derivative and simplifying, we obtain
$$f_N'(x) = \frac{\cos x (1 - \cos((2N + 2) x))}{(4N + 4) \sin^2 x}.$$
Since $\frac{\cos x (1 - \cos((2N + 2) x))}{(4N + 4) \sin^2 x} \ge 0$, it follows that the sign of $f_N'(x)$ is determined completely by $\cos x$.  Namely, $f_N'(x)$ is nonnegative on $(0, \pi/2]$, zero at $\pi/2$, and nonpositive on $[\pi/2, \pi)$.  It follows that $f_N(x)$ obtains a global maximum at $\pi/2$.  

Finally, note that 
\begin{align*}
f_N(\pi/2) &= \sum_{n=0}^N \frac{(-1)^n}{2n + 1} -  \frac{1}{2N+2}\sum_{n=0}^N(-1)^n.
\end{align*}
Since $f_{N+2}(\pi/2) > f_N(\pi/2)$, we can find the upper bound by taking the limit as $N \to \infty$, which gives 
$$\lim_{n \to \infty} f_N(\pi/2) = \sum_{n=0}^\infty \frac{(-1)^n}{2n+1} = \arctan{1} = \frac{\pi}{4}.$$
\end{proof}
\end{document}
