\documentclass[11pt]{scrartcl}
\usepackage[sexy]{evan}
\usepackage{graphicx}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb C}
\newcommand{\T}{\mathbb T}
\newcommand{\PP}{\mathbb P}
\newcommand{\supp}{\text{supp }}
\newcommand{\<}{\langle}
\renewcommand{\>}{\rangle}
\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}


\let \phi \varphi
\let \bar \overline

%From Topology
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cH}{\mathcal{H}}

\usepackage{answers}
\Newassociation{hint}{hintitem}{all-hints}
\renewcommand{\solutionextension}{out}
\renewenvironment{hintitem}[1]{\item[\bfseries #1.]}{}
\declaretheorem[style=thmbluebox,name={Problem}]{Prob}

\begin{document}
\title{Putnam Solutions}
\author{Vishal Raman}
\maketitle
\begin{abstract}
My sketches to problems from the Putnam exams.   I tend to leave out a lot of the details for routine checks or brute force calculations.  Any typos or mistakes found are mine - kindly direct them to my inbox.
\end{abstract}
\tableofcontents
\pagebreak
%\section{Putnam 1985}
%\subsection{A1 - Combinatorics} 
%\begin{Prob} Determine with proof, the number of ordered triples $(A, B, C)$ with $A\cup B\cup C = \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$ and $A \cap B \cap C = \emptyset$.   
%\end{Prob}
%\begin{proof}
%The Venn Diagram for $A, B, C$ has $7$ regions and we can place integers $1$ through $10$ in any of the regions except for the one corresponding to $A \cap B \cap C$.  This leads to $6^{10} = \boxed{2^{10} 3^{10} 5^0 7^0}$ possible ordered triples, since each configuration corresponds to a unique triple.  
%\end{proof}
%\subsection{A2 - Geometry}
%\begin{Prob} Let $T$ be an acute triangle. Inscribe a rectangle $R$ in $T$ with one side along a side of $T$. Then inscribe a rectangle $S$ in the triangle formed by the side of $R$ opposite the side on the boundary of $T$, and the other two sides of $T$, with one side along the side of $R$. For any polygon $X$, let $A(X)$ denote the area of $X$. Find the maximum value, or show that no maximum exists, of $\frac{A(R) + A(S)}{A(T)}$, where $T$ ranges over all triangles and $R, S$ over all rectangles as above.
%\end{Prob}
%\begin{proof}
%Drop a perpendicular from a vertex.  It suffices to maximize the ratio of areas for the left half since the ratio stays the same reflecting the triangle about the axis.  Let the height of the resulting triangle be $H$, the length $L$.  Split the height into 3 smaller heights $h_1, h_2, h_3$ so that $h_1 + h_2 + h_3 = H$.  Drawing a line parallel to the length through the heights gives the rectangles.  The lengths of the rectangles are
%$$\ell_1 = \frac{L}{H}h_1, \ell_2 = \frac{L}{H}(h_1 + h_2).$$
%
%The ratio is then given by 
%$$\gamma = \frac{A(R) + A(S)}{A(T)} = \frac{h_2\ell_1 + h_3\ell_2}{LH/2} = \frac{h_1h_2L/H + h_3(h_1+h_2)L/H}{LH/2} = \frac{2h_1h_2 + 2h_2h_3 + 2h_3h_1}{H^2}.$$
%Note that 
%$$H^2 = (h_1+h_2+h_3)^2 = h_1^2 + h_2^2 + h_3^2 + 2h_1h_2 + 2h_2h_3 + 2h_3h_1,$$
%so it follows that 
%$$\gamma = 1 - \frac{h_1^2+h_2^2+h_3^2}{(h_1+h_2+h_3)^2}.$$
%By the Cauchy-Schwarz Inequality,
%$$(h_1^2+h_2^2+h_3^2)(1+1+1) \ge (h_1+h_2+h_3)^2$$
%with equality when $h_1=h_2=h_3$.  Hence, $\gamma \le \boxed{2/3}$.  It is easy to show the equality case for an equilateral triangle of height $1$ with $h_1=h_2=h_3 = 1/3$.
%\end{proof}
%\subsection{A3 - Analysis}
%\begin{proof}  We claim that 
%$$\lim_{n \to \infty} a_n(n) = \begin{cases} 0, d = 0 \\
%e^{d}-1, d \ne 0
%\end{cases}.$$
%The $d=0$ case is clear, so we show the case where $d \ne 0$.  First, we prove that $a_m(n)+1 = (a_n(0)+1)^{2^{m}}.$  Note that $a_1(1) + 1 = a_1(0)^2 + 2a_1(0) + 1 = (a_1(0) + 1)^2$.  Suppose $a_n(k) + 1 = (a_n(0)+1)^{2^{k}}$ for some $k \in \N$.  Then
%$$a_{n}(k+1)+1 = a_{n}(k)^2 + 2a_n(k)+1 = (a_n(k) + 1)^2 = ((a_n(0)+1)^{2^k})^2 = (a_n(0) + 1)^{2^{k+1}},$$
%as desired.
%
%Plugging in the value of $a_n(0)$, we find that 
%$$a_n(n) = \left (\frac{d}{2^n} + 1\right )^{2^n} - 1 = \left (\frac{d}{2^n} + 1\right )^{\frac{2^n}{d} \cdot d} - 1.$$
%Taking the limit as $n \to \infty$, we find that 
%$$\lim_{n \to \infty} a_n(n) = \lim_{n \to \infty} \left (\frac{d}{2^n} + 1\right )^{\frac{2^n}{d} \cdot d} - 1 \xrightarrow{m = 2^n/d} \lim_{m \to \infty} \left (1+\frac{1}{m}\right )^{md} - 1 = e^{d} - 1.$$
%\end{proof}
%\pagebreak
\section{Putnam - 2001}
\subsection{A1 - Algebra}
 Consider a set $S$ and a binary operation $*$.  Assume $(a*b)*a = b$ for all $a, b \in S$.  Prove that $a*(b*a) = b$ for all $a, b \in S$. 
\begin{proof}
Note that 
$$b = ((b*a)*b) * (b*a) = a * (b * a).$$
\end{proof}
\pagebreak
\subsection{A2 - Combinatorics}
You have coins $C_1, C_2, \dots, C_n$.  For each $k$, $C_k$ is biased so that when tossed, is has probability $1/(2k+1)$ of falling heads.  If the $n$ coins are tossed, what is the probability that the number of heads is odd?

\begin{proof}
We claim the probability is $P(n) = \boxed{\frac{n}{2n+1}}$.  We prove it by induction.  We are given that $P(1) = \frac{1}{3}$, which satisfies the claim.  Suppose $P(k) = \frac{k}{2k+1}$ for $k \ge 1$.  In order to find $P(k+1)$, we condition on the result of the first $k$ coin tosses.  Namely, suppose the number of heads is even after $k$ tosses.  Then, the total number of heads is odd if we flip a head on the $k+1$-th toss.  Similarly, if the number of heads is odd after $k$ tosses, then the total number of heads is odd if we flip a tail on the $k+1$-th toss.  

Putting this together gives 
\begin{align*}
P(k+1) &= (1 - P(k))p_{k+1} + P(k)(1 - p_{k+1}) \\
&= P(k)\left (1 - 2p_{k+1}\right ) + p_{k+1} \\
&= P(k) \left (1 - \frac{2}{2k+3}\right ) + \frac{1}{2k+3} \\
&= P(k) \frac{2k+1}{2k+3} + \frac{1}{2k+3} \\
&= \frac{k}{2k+1} \frac{2k+1}{2k+3} + \frac{1}{2k+3} \\
&=\frac{k+1}{2k+3}
\end{align*}
which proves the result.
\end{proof}

\subsubsection{Official Solution}
There is another remarkable proof using generating functions.
\begin{proof}
Consider the polynomial $f(x) = \prod_{k=1}^n \left (\frac{x}{2k+1} + \frac{2k}{2k+1} \right)$.  The coefficient of $x^m$ gives the probability of exactly $m$ heads.  The sum of the odd coefficients is given by $\frac{f(1) - f(-1)}{2}$.  It is clear that $f(1) = 1$ and note that 
$$f(-1) = \prod_{k=1}^n \frac{2k-1}{2k+1} = \frac{1}{2n+1}.$$
The overall probability is $\frac{n}{2n+1}$ as desired.
\end{proof}
\pagebreak
\subsection{A3 - Algebra}
For each integer $m$, consider the polynomial $$P_m(x) = x^4 - (2m+4)x^2 + (m-2)^2.$$

For what values of $m$ is $P_m(x)$ the product of two non-constant polynomials with integer coefficients?

\begin{proof}
We claim that $m$ is the square of an integer or twice the square of an integer.  Set $y = x^2$.  We look for square-integer solutions for $y$.  From the quadratic formula,
\begin{align*}
y &= \frac{2m+4 \pm \sqrt{(2m+4) - 4(m-2)^2}}{2} \\
&= m+2 \pm \sqrt{(m+2)^2 - (m-2)^2 }\\
&= m+2 \pm \sqrt{4(2m)} \\
&= m + 2 \pm 2\sqrt{2m}\\
&= (\sqrt{m} \pm \sqrt{2})^2.
\end{align*}

Hence, $x = \pm \sqrt{m} \pm \sqrt{2}$.  Note that if $m$ is neither the square of an integer nor twice the square of an integer then the field $\Q(\sqrt{m}, \sqrt{2})$ is of degree $4$ and the Galois group acts transitively on the roots $\{\pm \sqrt{m} \pm \sqrt{2}\}$.  It follows that the polynomial is irreducible.

It is easy to verify that if $m$ is a square or twice a square, then $P_m(x)$ reduces into the product of non-constant integer polynomials.

%We must have $m = 2k^2$ for $k \in \Z$ in order for $y$ to be an integer.  It follows that 
%\begin{align*}
%y &= 2k+2 \pm 4k.
%\end{align*} 
%If $y = 2 - 2k$, then we must have $k = 0$ since $y \ge 0$ and $y$ must be a perfect square.  This gives a solution $m = 0$.
%
%If $y = 2 + 6k = 2(1+3k)$ we must have that $k$ is odd since $y$ is even and hence, must be divisible for $4$.  Thus, $k = 1 + 2\ell$ for $\ell \in \Z$.  This gives
%$$y = 2 (1 + 6\ell + 3) =4(2 + 3\ell).$$
%Taking the equation modulo $3$, we have
%$$y \equiv 1 \cdot 2 \equiv 2 \pmod{3},$$
%so it follows that $y$ cannot be a square since the quadratic residues of $3$ are $0$ and $1$.  
%
%Hence, we have the only possible solution $m = 0$.  It is easy to verify that 
%$$P_0(x) = x^4 - 4x^2 + 4 = (x^2 - 2)^2.$$
\end{proof}
\pagebreak
\subsection{A4 - Geometry}
Triangle $ABC$ has area $1$.  Points $E, F, G$ lie on sides $BC$, $CA$, $AB$ such that $AE$ bisects $BF$ at point $R$, $BF$ bisects $CG$ at point $S$, and $CG$ bisects $AE$ at point $T$.  Find the area of the triangle $RST$.

\begin{proof}
We claim that $[RST] = \frac{7- \sqrt{5}}{4}.$
Let $EC/BC = r$, $FA/CA = s$, $GB/AB = t$.

Note that $[ABE] = [AFE]$ since they share a base $AE$ and $BR = FR$ implies that the share the same altitude length as well(drop altitudes from $F$ and $B$ and use the congruent triangles).  

Then, $[ABE] = [ABE]/[ABC]= BE/BC = 1 - EC/BC = 1-r$.  We also have $[ACE] = r$.  It follows that $[FCE] = [ACE] (FC/AC) = r(1-s)$.

Now,
$$1 = [ABC] = [ABE] + [AFE] + [EFC] = (1-r) + (1-r) + r(1-s) \Longrightarrow r(1+s) = 1.$$
Arguing similarly for the other sides, we have $s(1+t) = 1$, and $t(1+r) = 1$.  

It follows that 
$$r = \frac{1}{1+s} = \frac{1}{1 + \frac{1}{1+t}} = \frac{1}{1 + \frac{1}{1 + \frac{1}{r}}}.$$

Simplifying this, we find that $r = \frac{2+r}{3 + 2r}$, which gives $3r + 2r^2 = 2+ r$, or equivalently, $r^2 + r - 1 = 0$.  Plugging into the quadratic formula and taking the positive root gives
$$r =\frac{-1 + \sqrt{5}}{2},$$
and by repeating the argument, we have $r = s = t = \frac{-1 + \sqrt{5}}{2}$.  

Now, note that $[ATC] = [AEC] / 2 = r/2$, $[ATG] = [ACG] - [ATC] = 1 - t - r/2$.  Similarly, $[BSC] = t/2$ and $[BRE] = 1 - r - s/2$, so it follows that $[BRTG] = [ABE] - [ATG] - [BRE] = r/2 + s/2 + t - 1$.
\begin{align*}
[RST] &= [ABC] - [ACG] - [BSC] - [BRTG] \\
&= 1 - (1 - t) - (t/2) - (r/2 + s/2 + t - 1)\\
&= 1 - \frac{r + s + t}{2} \\
&= 1 - \frac{3\frac{\sqrt{5} - 1}{2}}{2} \\
&= \frac{7 - \sqrt{5}}{4}.
\end{align*}
\end{proof}
\begin{proof}
A brute-force calculation through vectors.  Define $A$ to be the origin and take $B, C$ to be basis vectors from $A$.  We can set $G = \beta B$, $F = (1 - \gamma) C$, $E = \alpha C + (1 - \alpha) C$.  Furthermore, we set $R = (1 - \rho) E$, $S = \sigma B + (1 - \sigma )F$, $T = \tau C + (1 - \tau) G$.  To satisfy the conditions of the problem, we must have that 
$$2R = B+F, 2S = C + G, 2T =  E.$$

After messy algebra, we obtain that 
$$\alpha = \frac{1 - \beta}{2 - \beta}, \beta = \frac{1 - \gamma}{2 - \gamma}, \gamma = \frac{1 - \gamma}{2 - \gamma},$$
which has an obvious solution $\alpha = \beta = \gamma = \frac{3 - \sqrt{5}}{2}$.  

It follows that 
$$(R-T, S- T) = \frac{1}{2}\begin{pmatrix} \alpha & 2\alpha - 1 \\ 1 - 2\alpha & 1 - \alpha \end{pmatrix},$$
so we can evaluate 
$$[RST] = \frac{[ABC]}{4} \begin{vmatrix}
 \alpha & 2\alpha - 1 \\ 1 - 2\alpha & 1 - \alpha
\end{vmatrix}  = \frac{\alpha^2}{2} = \frac{7 - 3\sqrt{5}}{4}.$$
\end{proof}
\pagebreak
\subsection{A5 - Number Theory}
 Show that there are unique positive integers $a, n$ such that $a^{n+1} - (a+1)^n = 2001$.

\begin{proof}
We claim the unique pair of positive integers satisfying the claim is $(a, n) = (13, 2)$.  It is easy to verify that this is indeed a solution.  

Considering the equation in $\Z_3$, we see that $a \equiv 1 \pmod{3}$ - in the other cases, one of the terms vanishes and the other term is non-vanishing, so the difference cannot vanish.  

Considering the equation in $\Z_4$, we cannot have $a \equiv 0 \pmod{4}$, for the same reason as above.  If $a \equiv 1 \pmod{4}$, we must have that $n > 1$ in order for the equivalence to be satisfied.  If $a \equiv 2, 3 \pmod{4}$, we must have that $n$ is even.  

In the case with $a \equiv 1 \pmod{3}$ and $a \equiv 1 \pmod{4}$, we obtain $a \equiv 1 \pmod{12}$ and $n > 1$.   We see easily that $a = 1$ does not satisfy the equation for any $n > 1$.  For $a = 13$, we have a solution as above for $n = 2$.  It is easy to see that no higher value of $n$ also satisfies the equation since the function $f(x) = 13^{x + 1} - 14^x$ is monotonically increasing.   We can repeatedly apply similar arguments for the other cases to show that this is the unique solution.  
\end{proof}
\pagebreak
\subsection{A6 - Calculus}
 Can an arc of a parabola inside a circle of radius $1$ have a length greater than $4$?

\begin{proof}
We claim that it is possible.  Take a unit circle given by $x^2 + (y-1)^2 = 1$ and a parabola $y = kx^2$.  The length of the curve inside the arc is given by 
$$L(k) = 2\int_0^{\sqrt{2k-1}/k} \sqrt{1 + 4k^2 x^2}\,dx = \frac{1}{4k} \int_0^{2\sqrt{2k-1}} \sqrt{1 + x^2} \,dx.$$

It is easy to show that $\sqrt{1 +  x^2} \ge \frac{1}{x+1}$ so it follows that $\lim_{k \to \infty} L(k) = +\infty$.  It follows that there exists some $k$ so that $L(k) > 4$ as desired.  
\end{proof}
\pagebreak
\subsection{B1 - Combinatorics}
 Let $n$ be an even positive integer.  Write the numbers $1, 2, \dots, n^2$ in the squares of an $n \times n$ grid from left to right.  Color the squares of the grid so that half of the squares in each row and in each column are red and the other half are black.  Prove that for each coloring, the sum of the numbers on the red squares is equal to the sum of the numbers on the black squares.  

\begin{proof}
I have two proofs.  An outline of the first follows the approach of invariants.  Namely, we can start from a checkerboard pattern and repeatedly swap squares so that the sum of the numbers on the red squares is equal to the sum of the numbers on the black squares.  It suffices to show that the group of colorings with the given conditions is transitive under the transposition.  This is easy to show with an algorithm approach: for each square on a given board, we assign $1$ if it differs from the checkerboard, otherwise we assign $0$.  Then, we take the sum of the values.  We can choose transpositions so that the sum decreases on each turn, which must eventually terminate.  

The other approach is as follows.  For convenience, we subtract $1$ from each square so that it starts at $0$.  We can take the expansion in base $n$, so the value of each square $s$ is given by $nf(s) + g(s)$ where $0 \le f(s), g(s) < n$.  If we let $R$ denote the set of red numbers and $B$ the set of black numbers, note that $\sum_{s \in R} f(s) = \sum_{s \in B} f(s)$ since the number of red and black squares in each row is the same.  Similarly, $\sum_{s \in R} g(s) = \sum_{s \in B} g(s)$ since the number of red and black squares in each column is the same.  It follows that 
$$\sum_{s \in R} nf(s) + g(s) = \sum_{s \in B} nf(s) + g(s).$$
\end{proof}

\pagebreak
\subsection{B2 - Algebra} 
Find all pairs $(x, y) \in \R^2$ satisfying the system
\begin{align*}
\frac{1}{x} + \frac{1}{2y} &= (x^2 + 3y^2)(3x^2 + y^2) \\
\frac{1}{x} - \frac{1}{2y} &= 2(y^4 - x^4).
\end{align*}

\begin{proof}
An easy algebra exercise.  Expanding the right-hand sides, then adding/subtracting the equations, we obtain $(x+y)^5 = 3$ and $(x - y)^5 = 1$ respectively.  This has a unique solution in $\R^2$, $\left(\frac{3^{1/5} + 1}{2}, \frac{3^{1/5} - 1}{2} \right)$.
\end{proof}
\pagebreak
\subsection{B3 - Analysis} 
For any positive integer $n$, let $\<n\>$ denote the closest integer to $\sqrt{n}$.  Evaluate $\sum_{n=1}^\infty \frac{2^{\<n\>} + 2^{-\<n\>}}{2^n}$.

\begin{proof}
We reindex the sum by summing over the fixed values of $\<n\>$, which is non-decreasing.  Namely, we have 
$$\sum_{n=1}^\infty \frac{2^{\<n\>} + 2^{-\<n\>}}{2^n} = \sum_{m=1}^\infty \sum_{\<n\> = m}  \frac{2^{\<n\>} + 2^{-\<n\>}}{2^n} = \sum_{m=1}^\infty \left((2^m + 2^{-m})\sum_{\<n\> = m} 2^{-n}\right).$$

Note that $\<n\> = m$ whenever $n \in ((m-1/2)^2, (m+1/2)^2) = (m^2 - m+ 1/4, m^2 + m + 1/4)$.  This happens for $n \in [m^2 - m + 1, m^2 + m ]$.  Then, note that $$\sum_{n=m^2 - m + 1}^{m^2 + m} 2^{-n} = (1 - 2^{-m^2 - m}) - (1 - 2^{-m^2 + m}) = 2^{-m^2 + m} - 2^{-m^2 - m}.$$

Combining the results, we have 
\begin{align*}
\sum_{m=1}^\infty (2^{m} + 2^{-m}) (2^{-m^2 + m} - 2^{-m^2 - m}) &= \sum_{m=1}^\infty 2^{-m^2 + 2m} - 2^{-m^2 - 2m} \\
&= \sum_{m=1}^\infty 2^{-m(m-2)} - 2^{-m(m+2)} \\
&= \sum_{m=1}^\infty 2^{-m(m-2)} -  \sum_{m=3}^\infty 2^{-(m-2)m}  \\
&= 2^{1} + 2^{0} = 3.
\end{align*}
\end{proof}
\pagebreak
\subsection{B4 - Number Theory}
 Let $S = \Q \setminus\{-1, 0, 1\}$.  Define $f: S \to S$ by $f(x) = x - 1/x$.  Prove or disprove that 
$$\bigcap_{n=1}^\infty f^{(n)}(S) = \emptyset.$$
\begin{proof}
The claim is true.  Suppose we had $x = \frac{p}{q} \in \bigcap_{n=1}^\infty f^{(n)}(S)$, where $(p, q) = 1$.  Then, there is some $m \in \N$ so that $f^{(m)}(x) = x$.  However, note that 
$$f\left(\frac{p}{q} \right) = \frac{p^2 - q^2}{pq},$$
and $|pq| > |q|$ since $p \not \in \{-1, 0, 1\}$.  Furthermore, note that $(p^2 - q^2, pq) = 1$.  If there is some prime $r$ diving both $p^2 - q^2$ and $pq$, then we have that $r$ divides one of $p-q, p+q$ and one of $p, q$.  However, from these we could conclude that $r$ divides both $p, q$ which contradicts the fact that $(p, q) = 1$.  It follows that since the denominators strictly increase, we cannot have $f^{(m)}(x) = x$.
\end{proof}
\pagebreak
\subsection{B5 - Algebra}
let $a, b \in (0, 1/2)$ and let $g$ be a continuous real-valued function such that $g(g(x)) = ag(x) + bx$ for all real $x$.  Prove that $g(x) = cx$ for some constant $c$.
\begin{proof}
First, note that $g$ is injective.  This is because $g(x) = g(y)$ implies that $g(g(x)) = g(g(y))$, which implies that $ag(x) + bx = ag(y) + by$, which implies that $x = y$.   Since $g$ is continuous and injective, it follows that $g$ is monotone. 

We claim that $g$ is unbounded, which implies that it is surjective.  Suppose $|g(x)| \le M$ for all $x \in \R$.  Then, 
$$(a+1)M \ge |g(g(x)) - ag(x)| = |bx|,$$
which is a contradiction since $bx$ is unbounded.  

Now, let $x_0 \in \R$ be arbitrary and define $x_{n+1} = g(x_n)$, $x_{n-1} = g^{-1}(x_n)$.  The original functional equation gives a linear recurrence relation
$$x_{n+2} = ax_{n+1} + bx_n.$$
The corresponding characteristic polynomial is $\lambda^2 - a\lambda - b$, which has two distinct roots $\lambda_{\pm} = \frac{a \pm \sqrt{a^2 + 4b}}{2}$, since $a, b \in (0, 1/2)$.   It follows that 
$$x_n = c_+ \lambda_+^n + c_- \lambda_-^n$$
for constants $c_+, c_-$.

Note that $\lambda_+ > 0, \lambda_- < 0$ and $1 > |\lambda_+| > |\lambda_-|$.  

Suppose $f$ is monotone increasing(the case where $f$ is monotone decreasing is similar).  If $c_- \ne 0$ then as $n$ gets sufficiently small, $\lambda_-^n$ dominates $\lambda_+^n$, so there is some large enough $n$ so that $0 < x_n < x_{n+2}$ and $x_{n+3} < x_{n+1} < 0$, which would give that $g(x_n) > g(x_{n+2})$, a contradiction.  It follows that $c_- = 0$, so we have $x_0 = c_+$ and $g(x_0) = x_1 =  c_+ \lambda_+ = \lambda_+ x_0$, which gives the result.  


\end{proof}
\pagebreak
\subsection{B6 - Algebra/Combinatorics}
Assume $(a_n)_{n \ge 1}$ is an increasing sequence of positive real numbers such that $\lim a_n/n = 0$.  Must there exist infinitely many positive integers $n$ such that $a_{n-i} + a_{n+i} < 2a_n$ for $i = 1, 2, \dots, n-1$? 

%%\begin{proof}
%Let $A = \operatorname{Conv}\{(n, a_n): n \in \N\}$, and let $\partial A$ denote the set of points of $A$ that are on the boundary of the convex hull.  If $a_n \in \partial A$, there there exists some positive slope $m > 0$ so that the line through $a_n$ with slope $m$ is above all the other points of $A$.  In other words,
%$$a_k \le a_n + m(k-n),$$
%with equality at $k = n$.
%Furthermore, since $\frac{a_k}{k} \to 0$, we have that 
%$$\frac{a_k - a_n}{k-n} \to 0,$$
%and $\frac{a_k - a_n}{k-n} \le m$ for all $k$ so it follows that it attains a maximum for some $k = r$.
%\end{proof}
\begin{proof}
Let $A = \operatorname{Conv}\{(n, a_n) : n \in \N\}$ and let $\partial A$ denote the set of points on the boundary of the convex hull.  

We claim that $\partial A$ contains infinitely many elements.  Suppose not.  Then, $\partial A$ has a last point $(N, a_N)$.  If we let $m = \sup_{n > N} \frac{a_n - a_N}{n - N}$, the slope of the line between $(N, a_N)$ and $(n, a_n)$, then the line through $(N, a_N)$ with slope $m$ lies above(or contains) each point $(n, a_n)$ for $n > N$.  However, since $a_n/n \to 0$ and $a_N, N$ are fixed, we have that $$\frac{a_n - a_N}{n - N} \to 0.$$
This implies that the set of slopes attains a maximum, i. e. there is some point $(M, a_M)$ with $M > N$ so that $m = \frac{a_M - a_N}{M - N}$.  But then, we must also have that $(M, a_M) \in \partial A$, contradicting the fact that $(N, a_N)$ is the last point in $\partial A$.

For each point on the boundary $(n, a_n) \in \partial A$, we must have that midpoint of the line through $(n-i, a_{n-i})$ and $(n+i, a_{n+i})$ for $i \in [n-1]$ must lie below $(n, a_n)$.  From this, it follows that $a_n > \frac{a_{n-i} + a_{n+i}}{2}$, which implies the result.  
\end{proof}


\pagebreak
\section{Putnam - 2002}
\subsection{A1 - Algebra}
Let $k \in \N$.  The $n$-th derivative of $1/(x^{k}-1)$ has the form $P_n(x)/(x^{k}-1)^{n+1}$ where $P_n(x)$ is a polynomial.  Find $P_n(1)$.
\begin{proof}
We can write 
\begin{align*}
\frac{P_{n}(x)}{(x^k-1)^{n+1}} &= \frac{d}{dx} \left( \frac{P_{n-1}(x)}{(x^k - 1)^n}\right) \\
&= \frac{(x^k - 1)^n P_{n-1}'(x) - nkx^{k-1}(x^k - 1)^{n-1} P_{n-1}(x)}{(x^k - 1)^{2n}} \\
\Longrightarrow P_n(x) &= (x^k -1)P_{n-1}'(x) - nkx^{k-1}P_{n-1}(x).
\end{align*}

Plugging in $x = 1$ gives a recurrence relation $P_n(1) = -nk P_{n-1}(x)$.  It follows that $$P_n(1) = n!(-k)^n P_0(x) = n!(-k)^n.$$

\end{proof}
\subsubsection{Official Solution}
An alternate solution comes from expanding $\frac{1}{x^k - 1}$ in a Laurent series around $1$.  
\begin{proof}
It suffices to keep track of the $O((x-1)^{-1})$ terms since the others vanish upon plugging in $1$.

Note that 
$$\frac{1}{x^k - 1} = \frac{1}{k(x-1) + \dots} = \frac{1}{k} (x-1)^{-1} + \dots.$$
Taking the $n$-th, derivative, we have obtain 
$$\frac{d^n}{dx^n} \frac{1}{x^k - 1} = \frac{(-1)^n n!}{k(x-1)^{-n-1}} + \dots.$$
It follows that 
\begin{align*}
P_n(x) &= (x^k - 1)^{n + 1} \frac{d^n}{dx^n} \frac{1}{x^k - 1} \\
&= (k(x-1) + \dots)^{n+1} \left(\frac{(-1)^n n!}{k(x-1)^{-n-1}} + \dots \right) \\
&= k^n (-1)^n n! + \dots.
\end{align*}
\end{proof}
\pagebreak
\subsection{A2 - Combinatorics}
Given any five points on a sphere, show that some four of them must lie on a closed hemisphere.  
\begin{proof}
Draw a great circle through any two points and consider the remaining three.  By the pigeonhole principle, there is closed hemisphere with at least two points, and choosing this hemisphere gives the result.  
\end{proof}
\pagebreak
\subsection{A3 - Combinatorics}
Let $n \ge 2$ be an integer and $T_n$ the number of nonempty subsets $S$ of $\{1, 2, \dots, n\}$ with the property that the average of the elements of $S$ is an integer.  Prove that $T_n - n$ is always even.  
\begin{proof}
Note that each one element subset $\{1\}, \{2\}, \dots, \{n\}$ has the property that the average of the element is an integer.  It suffices to consider the subsets at least $2$ elements.  For set of size at least $2$, we can pair them into $(S, S \cup\{a\})$, where $a \not \in S$ and the average of the elements in $S$ is $a$.  Each subset is contained in exactly one pair, so each of them don't contribute to the parity of $T_n - n$.  It follows that $T_n - n$ is even as desired.  
\end{proof}

\pagebreak
\subsection{A4 - Combinatorics}
in Determinant Tic-Tac-Toe, Player 1 enters a 1 in an empty $3 \times 3$ matrix.  Player $0$ counters with a $0$ in a vacant position, and play continues in turn until the matrix is completed with five $1$'s and four $0$'s.  Player $0$ wins if the determinant is $0$ and player $1$ wins otherwise.  Who wins and how?
\begin{proof}
Player $0$ wins.  After exchanging rows and columns(which doesn't change the norm of the determinant), we can assume without loss of generality that player $1$ enters a $1$ in the $a_{11}$ square.  

In the optimal strategy, player $0$ enters a $0$ in the $a_{22}$ square.  There are 3 possible cases to check for player $1$'s next move:
\begin{enumerate}
\item $a_{12}$ or $a_{21}$,
\item $a_{13}$ or $a_{31}$,
\item $a_{23}$ or $a_{32}$,
\item $a_{33}$.
\end{enumerate}
For each of these cases, it suffices to check the first since we can exchange $a_{ij}$ with $a_{ji}$ in order to obtain the strategy in the other corresponding case.  Note that if player $0$ creates a row/column of $0$'s or a $2 \times 2$ block of $0$'s, the determinant of the matrix will be $0$.

(1) When player $1$ enters a $1$ in $a_{12}$, player $0$ enters a $0$ in square $a_{32}$. If player $1$ enters in $a_{21}$ or $a_{23}$, player $0$ enters in $a_{33}$ or $a_{31}$ respectively. In this position, player $1$ cannot stop player $0$ from creating a $2 \times 2$ block or a row of $0$'s.   Alternatively, if player $1$ enters in $a_{13}$, player $0$ enters in $a_{21}$.  In this position, player $1$ cannot stop player $0$ from creating a $2 \times 2$ block or a row of $0$'s.  In the other cases, we take a knight's move across whatever player $1$ plays and in this position, player $1$ cannot stop player $0$ from creating a $2 \times 2$ block or a row of $0$'s.

The other cases follow a similar analysis, creating a triangle block of $0$'s in other to create two threats.  
\end{proof} 
\pagebreak
\subsection{A5 - Number Theory}

Define a sequence by $a_0 = 1$, together with the rules $a_{2n+1} = a_n$ and $a_{2n+2} = a_n + a_{n+1}$ for each integer $n \ge 0$.  Prove that every positive rational number appears in the set $\{a_n/a_{n+1}: n \ge 0\}$.

\begin{proof}
We proceed by induction on $k = \max\{p, q: \gcd(p, q) = 1\}$.  For $k = 1$, we know that $a_0 = a_1 = 1$ so we have $1/1$, which contains all the rational numbers $p/q$ with $\max\{p, q\} \le 1$.  Suppose the set contains all the rationals $p/q$ with $\max\{p, q: \gcd(p, q) = 1\} \le n$.  Then it contains $\frac{n+1-k}{k}$ for $1 \le k \le n$ whenever $\gcd(n+1-k, k) = 1$.  Note that $\gcd(n+1 - k, k) = 1 \Leftrightarrow \gcd(n+1, k) = 1$.

It follows that we have $a_m = \ell(n + 1 - k), a_{m+1} = \ell(k)$ for some $\ell \in \N$.  Then, $a_{2m+1} = \ell(n+1-k)$, $a_{2n+2} = \ell(n+1)$ and $a_{2n+3} = \ell(k)$.  It follows that the set contains 
$$\frac{n+1-k}{n+1}, \frac{n+1}{k}$$
for each $1 \le k\le n$ so that $\gcd(n+1, k) = 1$, which proves the inductive step.  
\end{proof}

\pagebreak
\subsection{A6 - Analysis}
Fix an integer $b \ge 2$.  Let $f(1) = 1$, $f(2) = 2$, and for each $n \ge 3$, define $f(n) = nf(d)$, where $d$ is the number of base-$b$ digits of $n$.  For which values of $b$ does the sum $\sum_{n \ge 1} 1/f(n)$ converge?

\begin{proof}
The sum converges for $b = 2$ and diverges for $b \ge 3$.  

We first consider $b \ge 3$.  Suppose the sum converges.  Note that we can write 
$$\sum_{n = 1}^\infty \frac{1}{f(n)} = \sum_{d = 1}^\infty \frac{1}{f(d)}\sum_{n = b^{d-1}}^{b^{d} - 1} \frac{1}{n}.$$
Note that $\sum_{n = b^{d-1}}^{b^d - 1} \frac{1}{n}$ is a left-endpoint Riemann approximation for the integral $\int_{b^{d-1}}^{b^d} \frac{1}{x}$ and the function $\frac{1}{x}$ is monotonically decreasing on this interval so it follows that 
$$\sum_{n = b^{d-1}}^{b^d - 1} \frac{1}{n} > \int_{b^{d-1}}^{b^d} \frac{1}{x} = \log b.$$
However, this implies that 
$$\sum_{n = 1}^\infty \frac{1}{f(n)} > \log b \sum_{d = 1}^\infty \frac{1}{f(d)},$$
which is a contradiction since $\log b > 1$.


Now, we show that the sum converges in the case of $b = 2$.  Let $C = \log 2 + \frac{1}{8} < 1$.  We prove by induction that for each $m \in \N$, $$\sum_{n=1}^{2^{m} - 1} \frac{1}{f(m)} < 1 + \frac{1}{2} + \frac{1}{6(1-C)} = L.$$

For $m = 1, 2$, the result is clear.  Suppose it is true for all $m \in \{1, 2, \dots, N-1\}$.  Note that 
\begin{align*}
\sum_{n=1}^{2^N - 1} \frac{1}{f(n)} &= 1 + \frac{1}{2} + \frac{1}{6} + \sum_{d=3}^N \frac{1}{f(d)} \sum_{n = 2^{d - 1}}^{2^d - 1} \frac{1}{n}.
\end{align*}
Then, using a right-endpoint Riemann approximation, we have 
\begin{align*}
\sum_{n = 2^{d-1}}^{2^d - 1} \frac{1}{n} &= \frac{1}{2^{d - 1}} - \frac{1}{2^{d}} + \sum_{n = 2^{d-1}+1}^{2^d} \frac{1}{n} \\
&< 2^{-d} + \int_{2^{d-1}}^{2^d} \frac{dx}{x} \\
&< \frac{1}{8} + \log 2 = C.
\end{align*}
It follows that 
\begin{align}
1 + \frac{1}{2} + \frac{1}{6} + \sum_{d=3}^N \frac{1}{f(d)} &< 1 + \frac{1}{2} + \frac{1}{6} + C \sum_{d = 3}^N \frac{1}{ f(d)} \\
&< 1 + \frac{1}{2} + \frac{1}{6} + \frac{C}{6(1 - C)} \\
&= 1 + \frac{1}{2} + \frac{1}{6(1-C)} = L,
\end{align}
where we used the strong induction hypothesis to obtain $(2)$.
\end{proof}

\pagebreak
\subsection{B1 - Probability}
Shanille shoots free throws on a basketball court.  She hits the first and misses the second, and thereafter the probability that she hits the next shot is equal to the proportion of shots she has hit so far.  what is the probability she hits exactly $50$ of her first $100$ shots?
\begin{proof}
We claim the probability of hitting exactly $k$ shots after $n$ throws for $k \in \{1, \dots, n-1\}$is $\frac{1}{n-1}$.  For $n = 2$, this is clear.  If we suppose the result is true for $n = m$, the probability of making $k$ shots after $m + 1$ throws is 
$$\frac{k-1}{m} \cdot \frac{1}{m-1} + \frac{m - k}{m} \cdot \frac{1}{m-1} = \frac{m-1}{m(m-1)} = \frac{1}{m},$$
which proves the inductive hypothesis.  

\end{proof}
\pagebreak
\subsection{B2 - Combinatorics}
Consider a polyhedron with at least five faces such that exactly three edges emerge from each of its vertices. Two players play the following game: Each, in turn, signs his or her name on a previously unsigned face. The winner is the player who first succeeds in signing three faces that share a common vertex. Show that the player who signs first will always win by playing as well as possible.
\begin{proof}
First, we claim that any such polyhedron has a face with at least $4$ edges.  The proof is as follows.  Let $V, E, F$ denote the number of vertices, edges, and faces respectively.  For sake of contradiction, suppose that each face has exactly $3$ edges.  We can count the number of edges by counting $3$ edges for each face, but dividing by $2$ since each edge connects exactly $2$ faces.  It follows that $E = \frac{3F}{2}$.  Similarly, $V = \frac{2E}{3} = F$, since we can count two vertices for each edge, but dividing by $3$ since each vertex has exactly $3$ outgoing edges.  By Euler's formula, we have 
$$2 = V - E + F = 2F - \frac{3F}{2} = \frac{F}{2} \Longrightarrow F = 4,$$
which is a contradiction since $F \ge 5$.  

Now, take the face with at least $4$ edges, call it $F_0$.  Player $1$ signs in $F_0$.  If player $2$ does not sign in a face adjacent to $F_0$, then player $1$ can sign in any face adjacent to $F_0$.  At this point, player $2$ cannot stop player $1$ from signing three faces that share a common vertex since there are two threats.  Hence, we can suppose player $2$ does sign in a face adjacent to $F_0$, call it $F_1$.  Since the face has at least $4$ edges, we can sign in a square adjacent to $F_0$ that is not adjacent to $F_1$.  at this point, player $2$ cannot stop player $1$ from signing three faces that share a common vertex since there are two threats.  
\end{proof}

\pagebreak
\subsection{B3 - Analysis}
Show that for $n > 1$,
$$\frac{1}{2ne} < \frac{1}{e} - \left( 1 - \frac{1}{n} \right)^n < \frac{1}{ne}. $$
\begin{proof}
Multiplying by $e$ and subtracting from $1$, we have 
$$1 - \frac{1}{n} < e \left(1 - \frac{1}{n}\right)^n < 1 - \frac{1}{2n}.$$
Taking the logarithm(which is monotonically increasing), we equivalently have
$$\log(1 - 1/n) < 1 + n\log(1 - 1/n) < \log(1- 1/(2n)).$$
Finally, noting the Taylor series expansion of $\log(1 + x) = -\sum_{k \ge 1} \frac{(-x)^k}{k}$(which converges for $x \in (-1, 1)$), we have
$$-\sum_{k \ge 1} \frac{1}{kn^k}< 1 - n\sum_{k \ge 1} \frac{1}{kn^k} < -\sum_{k \ge 1} \frac{1}{k(2n)^k}$$
or equivalently
$$\sum_{k\ge 1}\frac{1}{k(2n)^k} < \sum_{k \ge 1} \frac{1}{(k + 1)n^k} <\sum_{k \ge 1} \frac{1}{kn^k},$$
which is evidently true since $k2^k > k + 1$ and $k+1 > k$ for $k \ge 1$.
\end{proof}
\pagebreak
\subsection{B4 - Combinatorics}
An integer $n$, unknown to you, has been randomly chosen in the interval $[1,2002]$ with uniform probability. Your objective is to select $n$ in an odd number of guess. After each incorrect guess, you are informed whether $n$ is higher or lower, and you $\textbf{must}$ guess an integer on your next turn among the numbers that are still feasibly correct. Show that you have a strategy so that the chance of winning is greater than $\tfrac{2}{3}$.

\begin{proof}
Guess the sequence of numbers $1, 3, 4, 6, 7, \dots$ alternating between $x \equiv 1 \pmod{3}$ and $x \equiv 1 \pmod{3}$.  If the chosen integer is  $1 \pmod{3}$, then it will be chosen in an odd turn.  If the chosen integer is $0 \pmod{3}$, then it will be chosen in an even turn.  Otherwise, it is $n \equiv 2 \pmod{3}$ so it will be chosen immediately after $n+1$ is chosen, which happens after an even turn, so it is an odd turn.  This gives a chance of winning of at least $2/3$ as desired.  
\end{proof}
\pagebreak
\subsection{B5 - Number Theory}
A palindrome in base $b$ is a positive integer whose base-$b$ digits read the same backwards and forwards; for example, $2002$ is a $4$-digit palindrome in base $10$. Note that $200$ is not a palindrome in base $10$, but it is a $3$-digit palindrome: $242$ in base $9$, and $404$ in base $7$. Prove that there is an integer which is a $3$-digit palindrome in base $b$ for at least $2002$ different values of $b$.
\begin{proof}
Let $N = 2002!$.  We claim that $N^2$ is a $3$-digit palindrome in base $b_d = \frac{N}{d} - 1$ for each $d \in \{1, 2, \dots, 2002\}$.  Note that $2d^2 < \frac{2002!}{d} - 1$ for each $d \in \{1, 2, \dots, 2002\}$.  It follows that we can write
\begin{align*}
([d^2][2d^2][d^2])_{b_d} &= d^2\left(\frac{N}{d} - 1 \right)^2 + 2d^2\left(\frac{N}{d} - 1 \right) + d^2 \\
&= N^2 - 2Nd - d^2 + 2Nd - 2d^2 + d^2 \\
&= N^2.
\end{align*}

\end{proof}
\pagebreak
\subsection{B6 - Number Theory}
Let $p$ be a prime number. Prove that the determinant of the matrix\[ \begin{bmatrix}x & y & z\\ x^p & y^p & z^p \\ x^{p^2} & y^{p^2} & z^{p^2} \end{bmatrix} \]is congruent modulo $p$ to a product of polynomials of the form $ax+by+cz$, where $a$, $b$, and $c$ are integers. (We say two integer polynomials are congruent modulo $p$ if corresponding coefficients are congruent modulo $p$.)
\begin{proof}
Note that the determinant $$P(x, y, z) = \sum_{\text{cyc}}x(y^pz^{p^2} - z^py^{p^2}),$$
which is a polynomial of degree $p^2 + p + 1$ in $x, y, z$.

Suppose not all of $a, b, c$ are zero.  Without loss of generality, $a \ne 0$.  Note that 
\begin{align*}
aP(x, y, z) &= \begin{vmatrix}
ax & y & z\\ ax^p & y^p & z^p \\ ax^{p^2} & y^{p^2} & z^{p^2}
\end{vmatrix} \\
&=  \begin{vmatrix}
ax +by + cz & y & z\\ ax^p +by^p + cz^p & y^p & z^p \\ ax^{p^2} +by^{p^2} + cz^{p^2} & y^{p^2} & z^{p^2}
\end{vmatrix} \\
&=  \begin{vmatrix}
ax +by + cz & y & z\\ a^px^p +b^py^p + c^pz^p & y^p & z^p \\ a^{p^2}x^{p^2} +b^{p^2}y^{p^2} + c^{p^2}z^{p^2} & y^{p^2} & z^{p^2}
\end{vmatrix} \\
&= \begin{vmatrix}
ax +by + cz & y & z\\ (ax +by + cz )^p & y^p & z^p \\ (ax +by + cz )^{p^2} & y^{p^2} & z^{p^2}
\end{vmatrix} \\
&= (ax+by+cz) \begin{vmatrix}
1 & y & z\\ (ax +by + cz )^{p-1} & y^p & z^p \\ (ax +by + cz )^{p^2-1} & y^{p^2} & z^{p^2}
\end{vmatrix} \\
\end{align*}
It follows that $P(x, y, z)$ divides $(ax+by+cz)$ whenever $a, b, c$ are not all zero in $\Z/p\Z$.  This includes $\frac{p^3 - 1}{p-1} = p^2 + p + 1$ terms(where we divide $p-1$ to account for scaling), which is exactly the degree of the polynomial.  Since $\Z/p\Z$ is a field, it is a unique factorization domain, so it follows that $P(x,  y, z)$ is exactly the product of $ax+by+cz$ for each  $a, b, c$ not all zero in $\Z/p\Z$(up to some constant), which proves the result.  
\end{proof}
\pagebreak

\section{Putnam 2003}
\subsection{A1 - Combinatorics}
Let $n$ be a fixed positive integer. How many ways are there to write $n$ as a sum of positive integers,
\[n = a_1 + a_2 + \cdots a_k\]with $k$ an arbitrary positive integer and $a_1 \le a_2 \le \cdots \le a_k \le a_1 + 1$? For example, with $n = 4$, there are four ways: $4$, $2 + 2$, $1 + 1 + 2$, $1 + 1 + 1 + 1$.
\begin{proof}
We claim that for each fixed positive integer $n$, there are exactly $n$ ways to write it as a sum of positive integers satisfying the above conditions.  We can prove this by induction on $n$  For $m = 1$, the result is clear.  Suppose it is true for $n = k$.  It suffices to prove the result for $n = k+1$.  By the inductive hypothesis, we can write $k = a_1 + a_2 + \dots + a_{\ell}$ in $k$ ways.  For each combination, note that if we take $b_\ell =  a_1 + 1$ and $b_j = a_{j+1}$ for $1 \le j \le \ell-1$, then 
$$k+1 = 1 + a_1 + \dots + a_\ell = b_1 + b_2 + \dots + b_{\ell}$$
is a valid combination for $k+1$.  There is exactly one indistinguishable way to group the extra $1$ since grouping with another $a_j = a_1$ is indistinguishable and if we group with $a_j = a_1 + 1$, then the overall sum does not satisfy the condition that the last term is bounded by one more than the first term.  Hence, we have exactly $k$ sums of the above form.  We have exactly one additional combination given by the sum of $k+1$ $1$'s, which is a total of $k+1$ ways, as desired.  

\end{proof}
\pagebreak
\subsection{A2 - Algebra}
Let $a_1, a_2, \cdots , a_n$ and $b_1, b_2,\cdots, b_n$ be nonnegative real numbers. Show that\[(a_1a_2 \cdots a_n)^{1/n}+ (b_1b_2 \cdots b_n)^{1/n} \le ((a_1 + b_1)(a_2 + b_2) \cdots (a_n + b_n))^{1/n}\]
\begin{proof}
This is a direct application of Holder's Inequality.  
\end{proof}
\subsubsection{Alternate Solution}
\begin{proof}
Note that 
\begin{align*}
\left (\frac{\prod_{k=1}^n a_k}{\prod_{k=1}^{n} (a_k + b_k)} \right)^{1/n} + \left (\frac{\prod_{k=1}^n b_k}{\prod_{k=1}^{n} (a_k + b_k)} \right)^{1/n} &= \left (\prod_{k=1}^n \frac{a_k}{a_k + b_k} \right)^{1/n} + \left (\prod_{k=1}^n \frac{b_k}{a_k + b_k} \right)^{1/n}  \\
&\le \frac{1}{n} \sum_{k=1}^n \frac{a_k}{a_k+b_k} + \frac{1}{n} \sum_{k=1}^n \frac{b_k}{a_k + b_k} \\
&= \frac{1}{n} \sum_{k=1}^n \frac{a_k + b_k}{a_k + b_k} \\
&= \frac{1}{n} \sum_{k=1}^n 1 = 1.  
\end{align*}
Multiplying both sides of the inequality by $\prod_{k=1}^n (a_k+b_k)^{1/n}$ gives the desired result.  
\end{proof}

\pagebreak
\subsection{A3 - Calculus}
Find the minimum value of\[|\sin{x} + \cos{x} + \tan{x} + \cot{x} + \sec{x} + \csc{x}|\]for real numbers $x$.
\begin{proof}
We claim the minimum value is given by $2\sqrt{2} - 1$.  Let $y = \pi/4 - x$.  Note that $$\sin{x} + \cos{x} = \sqrt{2} \cos(\pi/4 - x) = \sqrt{2} \cos y,$$
$$\sin{x} \cos{x} = \frac{1}{2} \sin(2x) = \frac{1}{2} \cos(\pi/4 - 2x) = \frac{1}{2} \cos{2y} = \cos^2 y - \frac{1}{2}.$$

Let $u = \sqrt{2} \cos y$.  
\begin{align*}
\sin x + \cos x + \tan x + \cot x + \sec x + \csc x &= \sin x + \cos x + \frac{1}{\sin x \cos x} + \frac{\sin x + \cos x}{\sin x \cos x} \\
&= u + \frac{2}{u^2 - 1} + \frac{2u}{u^2 - 1} \\
&= u + \frac{2(u + 1)}{u^2 - 1}.
\end{align*}
We wish to find the minimum value of $|f(u)|$ where $f(u) =  u + \frac{2(u + 1)}{u^2 - 1} $ and $u \in [-\sqrt{2}, \sqrt{2}]$.  Note that at for $u = -1$, the possible values of $y$ are $5\pi/4$ and $7\pi/4$.  At these values, the desired expression takes the values $2$ and $2 + \sqrt{2}$ respectively.  Assuming $u \ne 1$, we can write $f(u) = u + \frac{2}{u-1}$.  

Note that $$f(\sqrt{2}) = \sqrt{2} + \frac{2}{\sqrt{2} - 1} = \frac{4 - \sqrt{2}}{\sqrt{2} - 1} = 2 + 3\sqrt{2},$$
$$f(-\sqrt{2}) = -\sqrt{2} - \frac{2}{\sqrt{2} + 1} = -\frac{4 + \sqrt{2}}{\sqrt{2} + 1} = 3\sqrt{2} - 2.$$

Furthermore, $$f'(u) = 1 - \frac{2}{(u - 1)^2},$$
which has critical points at $u = 1 \pm \sqrt{2}$, but $1 + \sqrt{2}$ is outside of $[-\sqrt{2}, \sqrt{2}]$, so it suffices to check $u_0 = 1 - \sqrt{2}$.

At this point $$f(u_0) = 1 - \sqrt{2 } - \frac{2}{ \sqrt{2}} = 1 - 2\sqrt{2}.$$

Comparing all the critical values using the approximation $\sqrt{2} = 1.41 + O(|.01|)$, we find that the minimum possible value of $|f(u)|$ is given by $2\sqrt{2} - 1$.

\end{proof}
\pagebreak
\subsection{A4 - Algebra}
Suppose that $a, b, c, A, B, C$ are real numbers, $a \not= 0$ and $A \not= 0$, such that\[|ax^2+ bx + c| \le |Ax^2+ Bx + C|\]for all real numbers $x$. Show that\[|b^2- 4ac| \le |B^2- 4AC|\]
\begin{proof}
First, note that we must have that $|a| \le |A|$ which we can show by taking the limit in the given expression.  Let $\delta = b^2 - 4ac$, $\Delta = B^2 - 4AC$.  We can also define $p(x) = ax^2 + bx + c$ and $P(x) = Ax^2 + Bx + C$.  
%Note that $$ax^2 +bx + c = a\left(x - \frac{b}{2a}\right)^2 - \left (\frac{b^2 - 4ac}{4a} \right).$$
We proceed by cases on the sign on $\Delta$.
\begin{itemize}
\item Case 1: $\Delta > 0$.

In this case, we have that $P(x) = A(x-r_1)(x - r_2)$ for $r_1, r_2 \in \R$.  Then, we have that $|p(r_1)| \le |P(r_1)| = 0$ and $|p(r_2)| \le |P(r_2)| = 0$ so it follows that $p(x) = a(x-r_1)(x-r_2)$.  Since both polynomials have the same roots, it follows that $\frac{\sqrt{\delta}}{a} = \frac{\sqrt{\Delta}}{A}$, which is exactly the distance between $r_1$ and $r_2$.  It follows that 
$$|\delta| \le \frac{|a|^2}{|A|^2} |\Delta| \le |\Delta|.$$
\item Case 2: $\Delta = 0$.

In this case, we have that $P(x) = A(x-r)^2$ for $r \in \R$.  As before, we have that $p(r) = 0$.  Suppose that $p(x) = a(x-r)(x-s)$ for some $s \in \R$.  Note that we also have $P'(r) = 0$ since this is the vertex of the parabola.  If $s \ne r$, then we must have that $|p'(r)| > 0$ since $r$ is not the vertex.  It follows that the graphs of $|p(x)|$ and $|P(x)|$ intersect in the interval $[s, r]$(or $[r, s]$ depending on $r$), which is a contradiction.  It follows that $p(x) = a(x-r)^2$. Hence, $\delta = \Delta = 0$.

\item Case 3: $\Delta < 0$.  

In this case, we have that $P(x) = A(x-Z_1)(x-Z_2)$ for $Z_1, Z_2 \in \C$.  Note that $|P(x)|$ is minimized at $Z_* = \frac{Z_1+Z_2}{2}$.  Suppose that $p(x) = a(x - z_1)(x - z_2)$ and let $z_* = \frac{z_1+z_2}{2}$.  We have that 
$$\frac{|A(Z_1 - Z_2)^2|}{4} =  |P(Z_*)| \ge |P(z_*)| \ge |p(z_*)| = \frac{|a(z_1 - z_2)^2|}{4},$$
so it follows that $|z_1 - z_2| \ge |Z_1 -  Z_2|$ which proves that $|\delta| \le |\Delta|$ using the same method as in Case $1$.  
\end{itemize}


\end{proof}
\pagebreak
\subsection{A5 - Combinatorics}
A Dyck $n$-path is a lattice path of $n$ upsteps $(1, 1)$ and $n$ downsteps $(1, -1)$ that starts at the origin $O$ and never dips below the $x$-axis. A return is a maximal sequence of contiguous downsteps that terminates on the $x$-axis. For example, the Dyck $5$-path illustrated has two returns, of length $3$ and $1$ respectively. Show that there is a one-to-one correspondence between the Dyck $n$-paths with no return of even length and the Dyck $(n - 1)$ paths.

\[\begin{picture}(165,70)
\put(-5,0){O}
\put(0,10){\line(1,0){150}}
\put(0,10){\line(1,1){30}}
\put(30,40){\line(1,-1){15}}
\put(45,25){\line(1,1){30}}
\put(75,55){\line(1,-1){45}}
\put(120,10){\line(1,1){15}}
\put(135,25){\line(1,-1){15}}
\put(0,10){\circle{1}}\put(0,10){\circle{2}}\put(0,10){\circle{3}}\put(0,10){\circle{4}}
\put(15,25){\circle{1}}\put(15,25){\circle{2}}\put(15,25){\circle{3}}\put(15,25){\circle{4}}
\put(30,40){\circle{1}}\put(30,40){\circle{2}}\put(30,40){\circle{3}}\put(30,40){\circle{4}}
\put(45,25){\circle{1}}\put(45,25){\circle{2}}\put(45,25){\circle{3}}\put(45,25){\circle{4}}
\put(60,40){\circle{1}}\put(60,40){\circle{2}}\put(60,40){\circle{3}}\put(60,40){\circle{4}}
\put(75,55){\circle{1}}\put(75,55){\circle{2}}\put(75,55){\circle{3}}\put(75,55){\circle{4}}
\put(90,40){\circle{1}}\put(90,40){\circle{2}}\put(90,40){\circle{3}}\put(90,40){\circle{4}}
\put(105,25){\circle{1}}\put(105,25){\circle{2}}\put(105,25){\circle{3}}\put(105,25){\circle{4}}
\put(120,10){\circle{1}}\put(120,10){\circle{2}}\put(120,10){\circle{3}}\put(120,10){\circle{4}}
\put(135,25){\circle{1}}\put(135,25){\circle{2}}\put(135,25){\circle{3}}\put(135,25){\circle{4}}
\put(150,10){\circle{1}}\put(150,10){\circle{2}}\put(150,10){\circle{3}}\put(150,10){\circle{4}}
\end{picture}\]
\begin{proof}
Let $D_{n-1}$ be the set of $(n-1)$-Dyck paths and let $O_{n}$ ne the set of $n$-Dyck paths with no return of even length.  We can define functions $f: D_{n-1} \to O_n$ and $g: O_n \to D_{n-1}$ with $f \circ g = \id_{O_n}$ and $g \circ f = \id_{D_{n-1}}$.

We define $f$ as follows.  Let $p = a_1a_2\dots a_{2n-2} \in D_{n-1}$.  If $p$ has no return of even length, we can construct a path $f(p) = (1, 1)(1, -1)p \in O_n$.  Otherwise, suppose $p$ has at least one return of even length.  Suppose that $a_i \dots a_j$ is the last return of even length in $p$.  Then, we can define $f(p) = (1, 1) a_1 \dots a_i \dots a_j (1, -1) a_{j+1} \dots a_{2n-2}$.  This is in $O_n$ because the operation $f(p)$ removes all the returns before the last return of even length, which we extend to a return of odd length.  

Next, we define $g$.  Let $p = a_1a_2\dots a_{2n} \in O_n$.  Suppose $a_i \dots a_j$ is the first return of $p$.  We can define $f(p) = a_2 \dots a_i \dots a_{j-1} a_{j+1} \dots a_{2n}$.  This is in $D_{n-1}$ because $a_1 = (1, 1)$ and $a_j = (1, -1)$, so the remaining path remains above $0$ at all times.  

It is easy to verify that these functions satisfy the desired condition which gives the desired $1-1$ correspondence.  
\end{proof}
\pagebreak
\subsection{A6 - Combinatorics}
	For a set $S$ of nonnegative integers, let $r_S(n)$ denote the number of ordered pairs $(s_1, s_2)$ such that $s_1 \in S$, $s_2 \in S$, $s_1 \neq s_2$, and $s_1 + s_2 = n$. Is it possible to partition the nonnegative integers into two sets $A$ and $B$ in such a way that $r_A(n) = r_B(n)$ for all $n$?
\begin{proof}
WLOG suppose $1 \in A$, $0 \in B$.  Define $f(x) = \sum_{n \in A} x^n$,  $g(x) = \sum_{n \in B} x^n$ with $|x| < 1$.  Note that $f(x) + g(x) = \sum_{n=0}^\infty x^n = \frac{1}{1-x}$.  Furthermore, note that 
$$r_A(n) = [x^n] (f(x^2) - f(x)^2), r_B(n) = [x^n] (g(x^2) - g(x)^2),$$
where $[x^n](\cdot)$ denotes the $n$-th coefficient of the power series $\cdot$.  

We wish to show that there exists a choice $A \sqcup B = \N$ so that $f(x^2) - f(x)^2 = g(x^2) - g(x)^2$.  Equivalently, we have 
$$\frac{f(x) - g(x)}{f(x^2) - g(x)^2} = \frac{1}{f(x) + g(x)} = 1 - x,$$
and replacing $x \to x^{2^k}$ we obtain
$$\frac{f(x^{2^k}) - g(x^{2^k})}{f(x^{2^{k+1}} ) - g(x^{2^{k+1}})} = 1-x^{2^{k}}.$$

Taking the product of successive terms gives a telescoping product
$$f(x) - g(x) = \left(\prod_{k=0}^{n-1} (1 - x^{2^k}) \right) (f(x^{2^{n + 1}} ) - g(x^{2^{n+1}})).$$
Taking the limit as $n \to \infty$ and noting that $f(0) = 1$, $g(0) = 0$ by assumption, we have 
$$f(x) - g(x) = \prod_{k=0}^\infty (1 - x^{2^k}).$$

Furthermore, if we let $s_j = 0$ if $j \in A$, $s_j =1$ if $j \in B$, then we have 
$$f(x) - g(x) = \sum_{n=0}^\infty (-1)^{s_n} x^n = \prod_{k=0}^{\infty} (1-x^{2^k}).$$

The positive terms in the product correspond to an even number of terms, or equivalently the integers $n$ where the sum of the digits in the binary expansion is even.  It follows that taking $A$ to be the integers where the sum of the digits in the binary expansion is even and $B$ the integers where the sum of the digits in the binary expansion is odd satisfies the problem statement.
\end{proof}
\pagebreak
\subsection{B1 - Algebra}
Do there exist polynomials $a(x)$, $b(x)$, $c(y)$, $d(y)$ such that\[1 + xy + x^2y^2= a(x)c(y) + b(x)d(y)\]holds identically?
\begin{proof}
We claim no such polynomials exist.  
For a polynomial $P(x, y) = \sum_{i=0}^n \sum_{j=0}^n a_{ij} x^i y^j$ where $n$ is the degree of $P$, we can alternatively represent it with the matrix $A = (a_{ij})$.  Let $n = \max (\deg a, \deg b, \deg c, \deg y)$.  Note that $1 + xy + x^2y^2$ corresponds to the $n \times n$ matrix $P = (p_{ij})$ with $p_{11} = p_{22} =p_{33} = 1$ and $p_{ij} = 0$ for all other entries.  We can represent $a(x), b(x), c(y), d(y)$ with column and row vectors respectively given by $A, B, C, D$.  Note that $\rank(AC) \le \min(\rank A, \rank C)$ and the rank of the row and column vectors are at most $1$.  It follows that 
$$\rank(AC + BD) \le \rank{AC} + \rank{BD} \le 2,$$
but we know that $\rank P = 3$, so we cannot have $P = AC + BD$.
\end{proof}
\pagebreak
\subsection{B2 - Combinatorics} 
Let $n$ be a positive integer. Starting with the sequence $1,\frac{1}{2}, \frac{1}{3} , \cdots , \frac{1}{n}$, form a new sequence of $n -1$ entries $\frac{3}{4}, \frac{5}{12},\cdots ,\frac{2n -1}{2n(n -1)}$, by taking the averages of two consecutive entries in the first sequence. Repeat the averaging of neighbors on the second sequence to obtain a third sequence of $n -2$ entries and continue until the final sequence consists of a single number $x_n$. Show that $x_n < \frac{2}{n}$.
\begin{proof}
We claim that $x_n = \frac{2}{n} - \frac{1}{n2^{n-1}}$, which proves the result.   

First, we show by induction that the $j$-th entry of the $k$-th sequence is given by 
$$\frac{1}{2^{k-1}} \sum_{i=1}^{k} \frac{1}{i + j - 1} \binom{k-1}{i -1}.$$
For $k = 1$, the formula gives the desired starting sequence.  If we suppose it holds for the $k$-th row, then note that 
\begin{align*}
\frac{1}{2} &\left (\frac{1}{2^{k-1}} \sum_{i=1}^{k} \frac{1}{i + j - 1} \binom{k - 1}{i - 1} +  \frac{1}{2^{k-1}} \sum_{i=1}^{k} \frac{1}{i + (j + 1) - 1} \binom{k - 1}{i - 1} \right) \\
&= \frac{1}{2^k} \left (\frac{1}{j} + \frac{1}{k + j } + \sum_{i=2}^{k-1} \frac{1}{i + j } \left (\binom{k-1}{i-2} + \binom{k-1}{i-1} \right) \right) \\
&= \frac{1}{2^k} \left (\frac{1}{j} + \frac{1}{k + j } + \sum_{i=2}^{k-1} \frac{1}{i + j } \binom{k}{i-1}\right) \\
&= \frac{1}{2^k} \sum_{i=1}^{k} \frac{1}{i + j - 1 } \binom{k}{i-1}.
\end{align*}
Using this result, it follows that 
\begin{align*}
x_n &= \frac{1}{2^{n-1}} \sum_{i=1}^n \frac{1}{i} \binom{n-1}{i-1} \\
&= \frac{1}{2^{n-1}} \sum_{i=1}^n \frac{1}{n} \binom{n}{i} \\
&= \frac{1}{n2^{n-1}} (2^n - 1) \\
&= \frac{2}{n} - \frac{1}{n2^{n-1}}.
\end{align*}
\end{proof}
\pagebreak
\subsection{B3 - Number Theory}
Show that for each positive integer n,\[n!=\prod_{i=1}^n \; \text{lcm} \; \{1, 2, \ldots, \left\lfloor\frac{n}{i} \right\rfloor\}\](Here lcm denotes the least common multiple, and $\lfloor x\rfloor$ denotes the greatest integer $\le x$.)

\begin{proof}
Let $v(n)$ for $p$ prime, $n \in \N$ denote the exponent of $p$ in the prime factorization of $n$.  Note that 
\begin{align*}
v_p\left ( \prod_{k=1}^n \lcm \{1, 2, \dots, \floor{n/k}\}\right) &= \sum_{k=1}^n v_p \left (\lcm\{1, 2, \dots, \floor{n/k}\} \right) \\
&= \sum_{k=1}^n \floor{\log_p \floor{n/k}} \\
&= \sum_{k=1}^n \sum_{\ell : \floor{n/k} \ge p^\ell} 1 \\
&= \sum_{\ell=1}^\infty \floor{n/p^\ell}.
\end{align*}
This is exactly $v_p(n!)$ by Legendre's Theorem.  
\end{proof}
\pagebreak
\subsection{B4 - Algebra}
Let $f(z) = az^4+ bz^3+ cz^2+ dz + e = a(z -r_1)(z -r_2)(z -r_3)(z -r_4)$ where $a, b, c, d, e$ are integers, $a \not= 0$. Show that if $r_1 + r_2$ is a rational number, and if $r_1 + r_2 \neq r_3 + r_4$, then $r_1r_2$ is a rational number.
\begin{proof}
Let $s_1 = r_1 + r_2$, $s_2 = r_3 + r_4$, $p_1 = r_1r_2$, $p_2 = r_3r_4$.  Without loss of generality, we may assume $f$ is a monic polynomial with rational coefficients.  Note that we can write 
\begin{align*}
f(z) &= (z^2 - s_1z + p_1)(z^2 - s_2 z + p_2) \\
&= z^4 - (s_1 + s_2) z^3 + (p_1 + p_2 + s_1s_2)z^2 - (s_1p_2 + s_2p_1)z + p_1p_2.
\end{align*}
Now, note the following:
\begin{enumerate}
\item Since $-s_1 - s_2 = b \in \Q$ and $s_1 \in \Q$, we have that $s_2 = -s_1 - b \in \Q$.  
\item Since $p_1 + p_2 + s_1s_2 = c \in \Q$ and $s_1s_2 \in \Q$, we have that $p_1 + p_2 = c - s_1s_2 \in \Q$.
\item We can write 
\begin{align*}
d &= -s_1p_2 - s_2p_1 \\
&= -s_1p_2 - s_2p_1 + s_1p_1 - s_1p_1 \\
&= -s_1(p_1 + p_2) + (s_1 - s_2)p_1.
\end{align*}
Since $s_1 \ne s_2$, it follows that 
$$p_1 = \frac{d + s_1(p_1 + p_2)}{s_1 - s_2} \in \Q.$$
\end{enumerate}
\end{proof}
\pagebreak
\subsection{B5 - Geometry}
Let $A$, $B$ and $C$ be equidistant points on the circumference of a circle of unit radius centered at $O$, and let $P$ be any point in the circle's interior. Let $a$, $b$, $c$ be the distances from $P$ to $A$, $B$, $C$ respectively. Show that there is a triangle with side lengths $a$, $b$, $c$, and that the area of this triangle depends only on the distance from $P$ to $O$.

\begin{proof}
Let $\omega = e^{2\pi i / 3}$, $A = 1$, $B = \omega$, $C = \omega^2$, $P = z \in \C$ with $|z| < 1$.  We have 
$$a = |z - 1|, b = |z - \omega|,  c = |z - \omega^2|.$$

Note that 
\begin{align*}
(z - 1) + \omega(z - \omega) + \omega^2(z - \omega^2) &= z(1 + \omega + \omega^2) - (1 + \omega^2 + \omega^4) = 0.
\end{align*}
The corresponding triangle, where we visualize the complex numbers as vectors that are sides of the triangle, has side lengths of $a, b, c$ as desired.  

The area of the triangle is given by 
\begin{align*}
|(z-1) \bar{\omega(z - \omega)} - \bar{z - 1} \omega(z - \omega)|/4 &= |(z - 1) (\omega^2\bar{z} - \omega) - (\bar{z} - 1) (\omega z - \omega^2)|/4 \\
&= |z \bar{z} \omega^2 - \omega^2 \bar{z} - z\omega + \omega - z\bar{z} \omega + \omega z + \bar{z} \omega^2  - \omega^2|/4 \\
&= |(z \bar{z} - 1) (\omega^2 - \omega)|/4\\
&= \frac{(1 - |z|^2)\sqrt{3}}{4},
\end{align*}
which is a function of $z$, as desired. 
\end{proof}
\pagebreak
\subsection{B6 - Analysis}
Let $f(x)$ be a continuous real-valued function defined on $[0, 1]$.  Show that 
$$\int_{0}^1 \int_{0}^1 |f(x) + f(y)| \,dxdy \ge \int_0^1 |f(x)|\,dx.$$

\begin{proof}
Let $f^+ = \max(f(x), 0)$ and $f^- = f^+ - f$.  Let $A = \supp f^+$, $B = \supp f^-$.  We will denote $\|g\| = \int_{0}^1 |g(x)|\,dx$.

Note that 
$$\int_0^1 \int_0^1 |f(x) + f(y)|\,dxdy = \left (\iint_{A \times A} + \iint_{B \times B} + 2\iint_{A \times B} \right) |f(x) + f(y) | \,dxdy.$$

Note that 
\begin{align*}
\iint_{A \times A} |f(x) + f(y)| \,dxdy &= \iint_{A \times A} (f(x) + f(y)) \,dx dy \\
&= \iint_{A \times A} f(x) \,dxdy + \iint_{A \times A} f(y) \,dx dy \\
&=2|A| \|f^+\|.
\end{align*}
Similarly,
$\iint_{B \times B} |f(x) + f(y)| \,dxdy = 2|B| \|f^-\|$.

Finally, note that 
\begin{align*}
\iint_{A \times B} |f(x) + f(y)| \,dxdy & = \iint_{A \times B} |f^+(x) - f^-(y)| \,dxdy \\
&\ge \left | \iint_{A \times B} (f^+(x) - f^-(y))\,dxdy \right| \\
&= ||B| \|f^+\| - |A| \|f^-\||.
\end{align*}

Combining the results, we have that 
$$\int_{0}^1 \int_{0}^1 |f(x) + f(y)| \,dxdy \ge 2|A| \|f^+\| + 2|B| \|f^-\| + 2 ||B| \|f^+\| - |A| \|f^-\||.$$

Squaring both sides of the expression, we have that 
\begin{align*}
&\left (\int_{0}^1 \int_{0}^1 |f(x) + f(y)| \,dxdy \right)^2 \ge \left (2|A| \|f^+\| + 2|B| \|f^-\| + 2 ||B| \|f^+\| - |A| \|f^-\|| \right)^2 \\
&= 4 (|A| \|f^+\| + |B| \|f^- \| + ||B| \|f^+\| - |A| \|f^-\||)^2 \\
&= 4 (|A| \|f^+\| + |B| \|f^- \| )^2 + 4 (|B| \|f^+\| - |A| \|f^-\|)^2 + 8 (|A| \|f^+\| + |B| \|f^- \| )||B| \|f^+\| - |A| \|f^-\|| \\
&\ge 4(|A|^2 \|f^+\|^2 + |B|^2 \|f^-\|^2 + |A|^2 \|f^-\|^2 + |B|^2 \|f^+\|^2) \\
&\ge 4(|A|^2 + |B|^2) (\|f^+\|^2 + \|f^-\|^2) \\
&\ge (|A| + |B|)^2 (\|f^+\| + \|f^-\|)^2 \\
&= (1)^2 (\|f\|)^2 \\
&= \left (\int_0^1 |f(x)|\,dx \right)^2.
\end{align*}
\end{proof}
\pagebreak
\section{Putnum - 2004} 
\subsection{A1 - Number Theory}
Basketball star Shanille O'Keal's team statistician keeps track of the number, $S(N),$ of successful free throws she has made in her first $N$ attempts of the season. Early in the season, $S(N)$ was less than $80\%$ of $N,$ but by the end of the season, $S(N)$ was more than $80\%$ of $N.$ Was there necessarily a moment in between when $S(N)$ was exactly $80\%$ of $N$?
\begin{proof}
We claim that such a moment must exist.  Suppose not.  Then, there exists some value of $N$ so that 
$$\frac{S(N)}{N} < \frac{4}{5}, \frac{S(N) + 1}{N + 1} > \frac{4}{5}.$$

Cross-multiplying, this gives that $$5S(N) < 4N, 5S(N) > 4N -1,$$
but this system of inequalities has no solutions in integers.  
\end{proof}
\pagebreak
\subsection{A2 - Geometry}
For $i=1,2,$ let $T_i$ be a triangle with side length $a_i,b_i,c_i,$ and area $A_i.$ Suppose that $a_1\le a_2, b_1\le b_2, c_1\le c_2,$ and that $T_2$ is an acute triangle. Does it follow that $A_1\le A_2$?
\begin{proof}
We claim that it does follow.

Let $R_i$ be the angle between $a_i$ and $b_i$, $S_i$ the angle between $b_i$ and $c_i$ and $T_i$ the angle between $c_i$ and $a_i$.  Note that 
$$R_1 + S_1 + T_1 = R_2 + S_2 + T_2 = \pi,$$
so we must have at least one of $R_1 \le R_2$, $S_1 \le S_2$ or $T_1 \le T_2$.  Without loss of generality, suppose that $R_1 \le R_2$.  We have that 
$$A_1 = \frac{a_1b_1 \sin R_1}{2} \le \frac{a_2 b_2 \sin R_2}{2} = A_2,$$
as desired.
\end{proof}
%\section{Putnam - 2019}
%\subsection{A1 - Number Theory}
%\begin{Prob}[2019 - A1] Determine all possible values of the expression $$A^3 + B^3 + C^3 - 3ABC,$$
%where $A, B, C$ are nonnegative integers.
%\end{Prob}
%\begin{proof}
%Let $S = A^3 + B^3 + C^3 - 3ABC$.  We claim that $S$ attains all values such that $S \ne 3, 6 \pmod{9}$.
%
%Note that the expression can be factored as 
%$$A^3 + B^3 + C^3 - 3ABC = \left (\frac{A + B + C}{2}\right)\left((A-B)^2 + (B-C)^2 + (C-A)^2\right).$$
%
%If $(A, B, C) = (A, A+1, A+2)$, then 
%$$S = \frac{3A+3}{2}(1^2 + 1^2 + 2^2) = (3A + 3)(3) = 9A + 9,$$
%so we can achieve all $S \equiv 0 \pmod 9.$
%
%If $(A, B, C) = (A, A, A+1)$, then
%$$S = \frac{3A+1}{2}(0^2+1^2+1^2) = 3A+1,$$
%and if $(A, B, C) = (C+1, C+1, C)$, then 
%$$S = \frac{3C+2}{2}(0^2+1^2+1^2) = 3C+2,$$
%so we can achieve all $S \equiv 1, 2 \pmod{3}$.  
%
%It suffices to show that if $S \equiv 0 \pmod{3}$, then $S \equiv 0 \pmod{9}$.  This implies that we cannot have $S \ne 3, 6 \pmod{9}$ as desired.  If $S \equiv 0 \pmod{3}$, then we must have $A+B+C \equiv 0 \pmod 3$ or $(A-B)^2 + (B-C)^2 + (C-A)^2 \equiv 0 \pmod 3$.  In the first case, then without loss of generality, we must have either $(A, B, C) \in \{(0, 0, 0), (1, 1, 1),( 2, 2, 2), (0, 1, 2)\}$.  In each of these cases, we can show that $(A-B)^2 + (B-C)^2 + (C-A)^2 \equiv 0 \pmod 3$.  Similarly, in the second case, we must have that $(A-B)^2 = (B-C)^2 = (C-A)^2 = 0, 1$.  In the first case $A = B = C$, which gives that $A+B+C \equiv 0 \pmod{3}$.  In the second case, the remainders of $A, B, C$ must be distinct mod $3$, which, without loss of generality, gives $(A, B, C) = (0, 1, 2)$ which implies that $A+B+C \equiv 0 \pmod{3}$, as desired.  In all cases, we show that both terms in the product are $0 \pmod {3}$, which implies that the product is $0 \pmod {9}$.
%\end{proof}
%\subsection{A2 - Geometry}
%\begin{Prob}[2019 - A2] In the triangle $ABC$, let $G$ be the centroid, and let $I$
%be the center of the inscribed circle. Let $\alpha$ and $\beta$ be
%the angles at the vertices $A$ and $B$, respectively. Suppose that the segment $IG$ is parallel to $AB$ and that
%$\beta = 2\arctan(1/3)$. Find $\alpha$.
%\end{Prob}
%\begin{proof}
%We use complex numbers.  Let $B = 0$.  Then $\text{arg}(I) = \beta/2 = \arctan(1/3)$, so $I = k(3+i)$ for some $k \in \R^+$.  Without loss of generality, let $k = 1$.  Let $A = a$.  Then, $IG$ is parallel to $AB$ which implies that $\operatorname{Im}(B-A) = \Im(I-G)$.  Then $\Im(B-A) = 0$, so $\Im(I) = \Im(G) = 1$.  
%
%Then, note that $\arg(I^2) = \arg(C)$, so $C = \ell(3+i)^2 = \ell(8+6i)$ for some $\ell \in \R^+$.  Then $G = \frac{A+B+C}{3} = \frac{A+C}{3}$, so $$1 = \Im(G) = \Im((A+C)/3) = \Im(C/3),$$ which implies that $\ell = \frac{1}{2}$.  Thus, $C = 4+3i$.  
%
%Finally, $$I = \frac{|CB|A + |AC|B + |AB|C}{|AB|+|BC|+|CA|} = \frac{5a + a(4+3i)}{5+a+\sqrt{(4-a)^2+9}} = 3+i.$$
%
%Hence,
%$$5+a+\sqrt{(4-a)^2+9} = 3a,$$
%which has solutions $a = 0, a = 4$.  Taking the positive solution, we have $A = 4$.  Then, note that $ABC$ is a right triangle with right angle at $A$, so $\alpha = \frac{\pi}{2}$.
%\end{proof}
%\subsection{A3 - Analysis}
%\begin{Prob}[2019 - A3] Given real numbers $b_0, b_1, \dots, b_{2019}$ with $b_{2019} \ne 0$, let $z_1, z_2, \dots, z_{2019}$ be the roots in the complex plane of the polynomial $$P(z) = \sum_{k=0}^\infty b_kz^k.$$
%Let $\mu = \frac{1}{2019}\sum_{k=1}^{2019}|z_k|$.  Determine the largest constant $M$ such that $\mu \ge M$ for all choices of $b_0, b_1, \dots, b_{2019}$ satisfying 
%$$1 \le b_0 < b_1 < b_2 < \dots < b_{2019} \le 2019.$$
%\end{Prob}
%\begin{proof}
%By the AM-GM inequality,
%$$\mu = \frac{\sum_{k=1}^{2019}|z_k|}{2019} = \left (\prod_{k=1}^{2019} |z_k|\right )^{1/2019} = \left |\frac{b_0}{b_{2019}} \right|^{1/2019} \le (2019)^{-1/2019}.$$
%
%We show that $M = (2019)^{-1/2019}$.  Let $\zeta = e^{\frac{2\pi i}{2020}}$ and let $z_i = M\zeta^i$. Notice that $|z_i| = M$ for each $i$ and the roots $z_1, z_2, \dots, z_{2019}$ satisfy the polynomial
%$$0 = \frac{(z_i/M)^{2020} - 1}{(z_i/M) - 1} = M^{-2019}\left (\frac{z_i^{2020} - M^{2020}}{z_i - M}\right ) =\sum_{k=0}^{2019}z_i^{k}M^{-k}.$$
%
%Hence, the polynomial $$P(z) = \sum_{k=1}^{2019}z_i^k2019^{k/2019}$$
%satisfies the equality case $\mu = M$.  Furthermore, note that 
%$b_0 = 1$, $b_{2019} = 2019$ and and $2019^{i/2019} < 2019^{j/2019}$ for all $i < j$.  Hence, $P$ satisfies the conditions.
%\end{proof}

\end{document}
